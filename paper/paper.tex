%-----------------------------------------------------------------------------
%               Template for OOPSLA
%               based on:
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------
\documentclass[sigconf,review,anonymous]{acmart}
\acmConference[ESEC/FSE 2022]{The 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering}{14 - 18 November, 2022}{Singapore}
%\documentclass[runningheads,a4paper]{llncs}
%\documentclass[sigconf,authordraft]{acmart}
%\acmConference[ESEC/FSE 2017]{11th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering}{4--8 September, 2017}{Paderborn, Germany}
%\documentclass[10pt,numbers]{sigplanconf}
%\usepackage[1stsubmission]{oopsla2016}
%\usepackage[2ndsubmission]{oopsla2016}

%\usepackage[scaled]{helvet} % see www.ctan.org/get/macros/latex/required/psnfss/psnfss2e.pdf

%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}


\makeatletter
\newcommand{\removelatexerror}{\let\@latex@error\@gobble}
\makeatother


\usepackage{microtype}
\usepackage{url}                  % format URLs
\usepackage{listings}          % format code
\lstset{
  mathescape, 
  language={Java},
  numbers=left,
  stepnumber=1,
  basicstyle=\footnotesize
}
\usepackage{enumitem}      % adjust spacing in enums
%\usepackage[colorlinks=true,allcolors=blue,breaklinks,draft=false]{hyperref}   % hyperlinks, including DOIs and URLs in bibliography
% known bug: http://tex.stackexchange.com/questions/1522/pdfendlink-ended-up-in-different-nesting-level-than-pdfstartlink

\usepackage{graphicx}
\usepackage{float,subfig}
\usepackage{xspace,framed}
\usepackage{colortbl}
\usepackage{calc}
\usepackage[ruled,vlined]{algorithm2e}

%\usepackage{algorithm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{tikz}
\usepackage[justification=centering]{caption}
\usepackage{stmaryrd}
\usetikzlibrary{positioning, arrows, automata, shapes}
\usepackage{hhline}
\usepackage{pifont}
%\usepackage{cite}
\usepackage{pdflscape} % Experiments table is landscape
\usepackage{longtable}
\usepackage{afterpage}
\usepackage{wasysym}

\usepackage[justification=centering]{caption}
\input{macros}

%\setlength{\belowcaptionskip}{-10pt}
\setlength{\textfloatsep}{1em}
\setlength{\dbltextfloatsep}{1em}
\setlength{\abovecaptionskip}{0.1em}
% \floatsep: space left between floats (12.0pt plus 2.0pt minus 2.0pt).
% \textfloatsep: space between last top float or first bottom float and the text (20.0pt plus 2.0pt minus 4.0pt).
% \intextsep : space left on top and bottom of an in-text float (12.0pt plus 2.0pt minus 2.0pt).
% \dbltextfloatsep is \textfloatsep for 2 column output (20.0pt plus 2.0pt minus 4.0pt).
% \dblfloatsep is \floatsep for 2 column output (12.0pt plus 2.0pt minus 2.0pt).
% \abovecaptionskip: space above caption (10.0pt).
% \belowcaptionskip: space below caption (0.0pt).

\allowdisplaybreaks

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% uncomment for extended version 
\newcommand*{\extended}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% The following oopsla2016 options are available:
%
% 1stsubmission   For the initial submission
% 2ndsubmission   For the 2nd submission
% final           For camera-ready

\begin{document}

%\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
%\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

\title{Automatic refactoring of deprecated APIs} % guided by types and code hints}
%\subtitle{Subtitle Text, if any}
% double-blind submission
% single-blind only for Technical Research: http://icse2017.gatech.edu/technical-research-cfp
 % \authorinfo{Cristina David}
 %            {University of Oxford}
 %            {cristina.david@cs.ox.ac.uk}
 % \authorinfo{Pascal Kesseli}
 %            {University of Oxford}
 %            {pascal.kesseli@cs.ox.ac.uk}
 % \authorinfo{Daniel Kroening}
 %            {University of Oxford}
 %            {kroening@cs.ox.ac.uk}

\author{Cristina David}
\email{cristina.david@bristol.ac.uk}
\orcid{0000-0002-9106-934X}
\affiliation{
  \institution{University of Bristol}  
  \city{Bristol}  
  \country{UK}
  \postcode{BS8 1TH}
}
\author{Pascal Kesseli}
\affiliation{
  \institution{Diffblue}  
  \country{UK}
}
\author{Daniel Kroening}
\affiliation{
  \institution{Amazon}  
  \country{UK}
}


%% \author{
%% \mbox{Cristina David}\inst{1} \and
%% Pascal Kesseli\inst{2} \and
%% Daniel Kroening\inst{2}}

%% \institute{University of Bristol, UK 
%% \and
%%   University of Oxford, UK}

%% \author{Cristina David}
%% \affiliation{University of Oxford}
%% \email{cristina.david@cs.ox.ac.uk}

%% \author{Pascal Kesseli}
%% \affiliation{University of Oxford}
%% \email{pascal.kesseli@cs.ox.ac.uk}

%% \author{Daniel Kroening}
%% \affiliation{University of Oxford}
%% \email{kroening@cs.ox.ac.uk}

\begin{abstract}
  As a project evolves, certain fields, methods or classes are
  marked as deprecated in a bid to discourage their future
  use. When done manually, refactoring legacy code in order to eliminate uses of
  deprecated APIs is an error-prone and time-consuming process. In
  this paper, we propose an automated program refactoring technique
  that eliminates such uses of deprecated APIs by incorporating
  semantic information about the code. Our refactoring procedure
  performs semantic reasoning and search in the space of possible
  refactorings using automated program synthesis. In particular, the
  program synthesis is guided by code hints and type information and makes use of
  coverage-guided property-based testing. %% We
  %% encode both the synthesis of refactoring candidates and their
  %% verification as program safety problems that we then solve with
  %% coverage-guided property-based testing.
  We implemented our
  technique in the tool ?? and used it to refactor a considerable
  proportion of the methods deprecated in jdk15.
  %
  %% Refactorings are structured changes to existing software that leave its
  %% externally observable behaviour unchanged.  Their intent is to improve
  %% readability, performance or other non-behavioural properties. 
  %% State-of-the-art automatic refactoring tools are {\em syntax}-driven and,
  %% therefore, overly conservative.  In this paper we explore {\em
  %% semantics}-driven refactoring, which enables much more sophisticated
  %% refactoring schemata.  As~an exemplar of this broader idea, we present
  %% an automatic refactoring tool that replaces uses of deprecated legacy APIs/libraries
  %% with the latest ones.
  %% Our refactoring procedure performs
  %% semantic reasoning and search in the space of possible refactorings using
  %% automated program synthesis.  Our experimental results support the
  %% conjecture that semantics-driven refactorings are more precise and are
  %% able to rewrite more complex code scenarios when compared to syntax-driven
  %% refactorings.
%
\end{abstract}

\maketitle

%\keywords{program refactoring, program synthesis, program verification}

%\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore, 
% you may leave them out
%\terms
%term1, term2

%% \keywords
%% Maintenance and reuse



\section{Introduction}\label{sec:intro}

As a project evolves, there are certain fields, methods or classes
that the developers are discouraged from using in the future as
they've been superseded and may cease to exist in the future.
However, removing them directly would break the backward compatibility
of the project's API.  Instead, such elements can be tagged with the
\texttt{@Deprecated} annotation.  %% In general, when deprecating a
%% field/method/class, the \texttt{@deprecated} Javadoc tag is used in the
%% comment section to inform the developer the reason of deprecation and
%% what can be used in place.


%Even in the presence of such recommendations,
The transformation of existing code such that it doesn't use deprecated APIs
%to the recommended format
is not always straightforward,
as illustrated in Fig.~\ref{ex:deprecated-method-other}. In the example, we
make use of the \texttt{getHours} method of the \texttt{Date} class,
which is deprecated.
%% with the 
%% recommendation to use \texttt{Calendar.get(Calendar.HOUR\_OF\_DAY)} instead.
In this situation, in order to replace the use of the deprecated method,
we must first obtain a \texttt{Calendar} object.
However, we can't use the \texttt{Calendar} constructor as it is protected,
and we must instead call \texttt{getInstance}.
Furthermore, in order to be able to use this \texttt{Calendar} object for our purpose,
we must first set its time using the existing \texttt{date}.
We do this by calling \texttt{setTime} with \texttt{date} as argument.
%% followed by setting the date using \texttt{set}
%% and returning a Date object by invoking \texttt{getTime}.
%% Alternatively, the \texttt{GregorianCalendar} class may be used with
%% similar difficulties.
Finally, we can retrieve the hour by calling
%Only after all this set up, we can finally make use of the recommendation
\texttt{calendar.get(Calendar.HOUR\_OF\_DAY)}.

\begin{figure}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
void main(String[] args) {
  // Deprecated:
  int hour = date.getHours();
  
  // Should have been:
  final Calendar calendar = Calendar.getInstance();
  calendar.setTime(date);
  int hour = calendar.get(Calendar.HOUR_OF_DAY);
}
\end{lstlisting}
\caption{Deprecated method example.}
\label{ex:deprecated-method-other}
\end{figure}


While it is trivial for IDEs such as Eclipse or IntelliJ IDEA to
recognise the use of deprecated APIs and warn the programmer about it,
refactoring the code to a preferred API is significantly more
complex. Indeed neither Eclipse 4.15.0 nor IntelliJ IDEA 2020.2.2 make
any attempt to suggest an alternative to the user.

With respect to the work pursued by the academic community, 
the closest paper to our current proposal
%aims to replace the
%deprecated usages,
replaces calls
to deprecated methods by their
bodies~\cite{DBLP:conf/paste/Perkins05}.  The issue is that, this
strategy doesn't usually follow the intention of the language designers, who
use deprecation to signal that there is a safer and generally better
way of achieving a given goal.  Moreover, inlining calls to deprecated
methods can cause undesirable effects if the original function was
synchronised.  While it is not possible for two invocations on the
same object of the synchronised original method to interleave, this is
not guaranteed after inlining the method's body.

%% There is also
%% very limited support offered by the research community, mainly
%% focusing on replacing calls to deprecated methods by their
%% bodies~\cite{DBLP:conf/paste/Perkins05}. 

Another closely related class of works focuses on API adaptation after library updates~\cite{DBLP:conf/icse/WuGAK10,DBLP:conf/kbse/Huang0PW021}. These works use techniques such as call dependency and text similarity analyses to automatically identify change rules linking different library releases. Essentially, a change rule describes a match between methods existing in the old release but which have been removed or deprecated in the new one, and replacement methods in the new release. For instance, for our running example in Figure~\ref{ex:deprecated-method-other}, a change rule would inform the programmer that  method \texttt{getHours} from class \texttt{Date} must be replaced by method \texttt{get} from class \texttt{Calendar}. Notably, {\em change rules are different from refactorings} as they don't provide the actual replacement code. Instead, the programmer is still required to perform a lot of the work
manually: for instance, she has to figure out lines 6--8 for the refactoring in Figure~\ref{ex:deprecated-method-other}. This is a time-consuming and error-prone process, especially as the
responsibility of guaranteeing that the refactored code maintains the original behaviour
is left to the programmer.
%% programmer
%% is left to guarantee that the way in which she performed the replacement
%% does not change the functionality of
%% the code. Indeed, the hardest part about such refactorings is that they must preserve observational equivalence, i.e. they must preserve the code's behaviour.

%% For instance, in~\cite{}, Huang et al. attempt to find replacements for missing APIs
%% (an API is considered as a public method in a public class). This includes APIs
%% that have been deprecated.
%% A crucial remark is that, in general, API adaptation can be decomposed into two tasks; i.e., the first is to find what is the replacement of a missing API (e.g., [13, 18, 89, 95]),
%% and the second is to identify how usages of a missing API are actually replaced by usages of its replacement API (e.g., [24, 81]).
%% Basically, this means that the former task only finds alternative APIs, but without providing ways in which these alternatives can
%% be used. For instance, for the motivational example, it might say that the code hint needs to be used, but not how.

%% In the current work, we perform both tasks, meaning that we provide the exact lines of code
%% to replace the deprecated usage. While we do not provide absolute guarantees about
%% the correctness of our suggestion, our suggestions have been tested on a minimum of X inputs.

%%usually such change rules only fix the syntactic difference



%% Consequently, the majority of
%% refactorings removing deprecated instances are done manually, which is a costly,
%% time-intensive, and not least error-prone process.  This situation is
%% also a real issue for legacy code that makes use of deprecated APIs
%% that need to be replaced with latest APIs/libraries.

%% The main cause of difficulty when replacing deprecated instances lies
%% with the fact that refactorings should not change the functionality of
%% the code, i.e., they must preserve observational equivalence.
%% Ensuring observational equivalence is far from trivial.


For
illustration, when referring back to the example in
Figure~\ref{ex:deprecated-method-other}, it's not immediately
obvious that the original and the refactored code behave in the same manner.
One needs a good understanding of the
code's semantics in order to reach such a conclusion.
%
%% For instance,
%% inlining calls to deprecated methods can break equivalence if the
%% original function was synchronised.  While it is not possible for two
%% invocations  on the same object of the synchronised original method to
%% interleave, this is not guaranteed after inlining the method's body.
%% Fig.~\ref{ex:unsound-refactoring-original} and
%% Fig.~\ref{ex:unsound-refactoring-refactored} illustrate an example where
%% the "Extract Local Variable..." refactoring integrated in Eclipse 4.21.0
%% inadvertently removes synchronisation for the evaluation of the expression
%% $x > 0$.
%
%% \begin{minipage}{.23\textwidth}
%% \begin{lstlisting}[mathescape=true,showstringspaces=false]
%
%% synchronized (this) {
%%   if (x > 0) {
%%     foo();
%%   }
%% }
%% // ...
%% synchronized (this) {
%%   if (x > 0) {
%%     bar();
%%   }
%% }
%% \end{lstlisting}
%% \captionof{figure}{Concurrent example.}
%% \label{ex:unsound-refactoring-original}
%% \end{minipage}
%% \begin{minipage}{.23\textwidth}
%% \begin{lstlisting}[mathescape=true,showstringspaces=false]
%% boolean tmp = x > 0;
%% synchronized (this) {
%%   if (tmp) {
%%     foo();
%%   }
%% }
%% // ...
%% synchronized (this) {
%%   if (tmp) {
%%     bar();
%%   }
%% }
%% \end{lstlisting}
%% \captionof{figure}{Unsound refactoring.}
%% \label{ex:unsound-refactoring-refactored}
%% \end{minipage}
%% \vspace{0.8em}
%
%% Another example of a refactoring that unintuitively breaks
%% observational equivalence is given in Figure~\ref{}.
%% \todo{add example here.}
%
Indeed, refactorings that rely solely on a program's syntax
and do not consider its semantics end up
being overly conservative, mostly addressing structural changes
to the program.  
The observation that 
%Ohter works have made the observation that 
refactoring generally benefits from semantic analyses of a program is not new, e.g. previous works made use of program invariants~\cite{Kataoka:2001:ASP:846228.848644}, or types~\cite{Steimann2011,Steimann2012Pilgrim,Steimann2011KollePilgrim}.
%% Notably, the limitations of syntax-driven refactorings have been observed
%% in several works, resulting in an emerging trend to incorporate more {\em semantic}
%% information into refactoring decisions, such as Abstract Syntax Tree (AST) 
%% type information,
%% further preventing compilation errors and behaviour changes
%% \cite{Steimann2011,Steimann2012Pilgrim,Steimann2011KollePilgrim}.


%
%% such refactorings are based on semantics rather
%% than syntax. For illustration, let's refer back to the example in
%% Figure~\ref{ex:deprecated-method}.  A {\em syntax-driven refactoring}
%% addresses structural changes to the program requiring only limited
%% information about a program's semantics, whereas a {\em
%%   semantics-driven refactoring} requires detailed understanding of the
%% program semantics in order to be applied soundly.  Clearly, the
%% refactoring of the call to the deprecated \texttt{Date} constructor
%% falls into the latter category. 
%
%\subsection{From the previous introduction:}
%% Refactorings are structured changes to existing software which leave its
%% externally observable behaviour unchanged.  They improve non-functional
%% properties of the program code, such as testability, maintainability and
%% extensibility while retaining the semantics of the program.  Ultimately,
%% refactorings can improve the design of code, help finding bugs as well
%% as increase development speed and are therefore seen as an integral part
%% of agile software engineering processes~\cite{DBLP:conf/xpu/Kerievsky04b,
%% Fowler1999}.
%
%% However, manual refactorings are a costly, time-intensive, and not least
%% error-prone process.  This has motivated work on automating specific
%% refactorings, which promises safe application to large code bases at low
%% cost.  We differentiate in this context between {\em syntax-driven} and {\em
%% semantics-driven} refactorings.  While the former address structural changes
%% to the program requiring only limited information about a program's
%% semantics, the latter require detailed understanding of the program
%% semantics in order to be applied soundly.  An example of a refactoring that
%% requires a semantics-driven approach is {\em Substitute Algorithm}, where an
%% algorithm is replaced by a clearer, but equivalent
%% version~\cite{Fowler1999}.
%
%AST-based constraints 
%
%% A syntax-driven approach is insufficient to perform such substantial
%% transformations.  Figure~\ref{ex:syntax-limits} illustrates this using an
%% example: Both loops in the code implement the same behaviour.  In order to
%% recognise this and apply {\em Substitute Algorithm}, pattern-based
%% approaches need explicit patterns for vastly different syntaxes implementing
%% the same semantics, which is infeasible for practical applications.
%
%% \todo{I've removed the reference to Move Field as it's a bit controversial given that
%% Steinmann uses it to explain that purely syntactic approaches are not enough.}
%
%% use constraints involving the abstract syntax tree type 
%% information in order to handle the {\em Move Field} (when a field
%% is used by another class more than the class on which it is defined)
%% of syntax-driven, e.g.  
%% An example 
%% of a refactoring that is well handled by the syntax-driven approach 
%% implemented using constraints over the program's abstract syntax tree
%% There is an emerging trend to incorporate more {\em semantic}
%% information into refactoring decisions, such as AST type information,
%% further preventing compilation errors and behaviour changes
%% \cite{Steimann2011}.

\paragraph{Program refactoring via program synthesis} In this paper, we propose an
automated refactoring technique for replacing uses of deprecated APIs. 
The proposed technique makes use of program synthesis in order to
incorporate semantic information about the
code into the refactoring process.
%take a step further in this direction by proposing a
%semantics-driven refactoring technique that makes use of program synthesis.
While we focus on the refactoring of deprecated methods, the same
technique can be applied to deprecated fields and classes.
%Our goal is to design a refactoring techniques for deprecated instances that computes refactorings fast, thus allowing integration with an IDE.

%% As explained in more detail in the overview in Section~\ref{sec:overview},
%% the program synthesis technique will be guided by {\em code hints}
%% and {\em types}, as well 

Although powerful, program synthesis is very hard due to the vast search space, i.e.~the space of possible programs that must be considered. Thus, its success is generally reliant on how efficiently it is guided towards a solution by discarding uninteresting programs as early as possible. Most commonly, the information used to guide the search is represented by input/output examples~\cite{DBLP:conf/pldi/FeserCD15}, type signatures~\cite{DBLP:conf/pldi/OseraZ15}, or full functional specifications of the expected code~\cite{DBLP:conf/ijcai/MannaW79}.
%
The vast search space is particularly a challenge in the current setting given that, in the absence of any additional guidance, the entire \texttt{java.lang} could be considered when synthesising the refactoring.
In order to prune the search space, we start by investigating the information available to our refactoring procedure.
%The information that we are going to use to direct
%\begin{itemize}

{\bf (1)} {\em Type information} about the code to be generated. In particular, this consists on the types of the objects to be consumed (i.e. the inputs), as well as the types of the objects that need to be produced (i.e. the outputs). As mentioned above, types are commonly used to guide  program synthesis. In the example in Figure~\ref{ex:deprecated-method-other}, the \texttt{date} object can be seen as an input with type \texttt{Date}, whereas \texttt{hour} of type \texttt{int} is considered an output.
However, as shown by our experimental evaluation in Section~\ref{sec:experimental-results}, while useful, types are not sufficient to solve the problem. %, where the number of possible programs where considering \texttt{java.lang} %\cite{DBLP:conf/popl/FengM0DR17} \todo{add more citations}.

{\bf (2)} {\em Code hints} present in the Javadoc comments. In general, when deprecating a field/method/class, the \texttt{@Deprecated} Javadoc tag is used in the
  comment section to inform the developer of the reason for deprecation and what can be used in its place. As we will show in Section~\ref{sec:overview}, these hints
  don't provide the whole refactoring, but can be used to guide the search process.
While code hints have been previously used to generate change rules~\cite{DBLP:conf/kbse/Huang0PW021}, our aim is to generate complete refactorings.
  
  {\bf (3)} Finally, the key criterion we have for the code to be generated is that it needs to be {\em semantically equivalent to the original}, meaning that they must preserve its behaviour. %While this does provide us with the {\em semantics of the
  %code to be generated}, it's not easy to use. 
%* This is not enough to decide semantic equivalence, which, as discussed above, is one of the main difficulties in this refactoring.
  However, formally proving semantic equivalence is expensive and undecidable in the general case. %very difficult, having been the subject of extended research over the years \cite{}.
%Even when theoretically possible, the process of proving semantic equivalence is very expensive as it generally requires full understanding of the code's semantics.
%Moreover, it generally requires full understanding of a program's internal structure, which is expensive.
%This contradicts our aforementioned goal to design a technique that is fast. In a bid to obtain good performance,
%we investigated using greybox testing for checking program equivalence, rather than formally proving it.
In this work, instead of aiming for a formal proof,  we use coverage-guided property-based testing to check equivalence. %, which only requires limited instrumentation of the programs under test.
While we can't provide full correctness guarantees,
our experiments show that, when considering a large number of test inputs, the refactorings do indeed preserve the behaviour of the original code.

%Then, we choose a compromise between performance and ease of use and soundness. We use ...

%{\em Following the same principle, we design a greybox synthesis technique that is guided by code hints and types.}


%% For this purpose, we make use of component-based program synthesis, which assembles programs
%% from a library of existing components, e.g. methods provided by an API.
%% One of the challenges in component-based synthesis is the large number of components
%% when considering real-world APIs. Specifically for our use case, when generating Java code, we have
%% access to the whole of Java standard library.
%% We address this challenge by using the code hints provided in the Javadoc comments
%% (under the Javadoc \texttt{@code} tag) and type information to prune the component
%% library before the actual synthesis process.

%% With respect to the synthesis process, we propose using greybox
%% synthesis. Traditionally, synthesis techniques are either based
%% on whitebox or blackbox approaches.  The former are fully aware of the
%% internal structure of the program being synthesised, whereas the
%% latter only examine its functionality. In this paper, we use a greybox
%% approach, which relies on coverage-guided property-based testing. 
%% For this purpose, we provide an encoding for the synthesis problem, which
%% makes it amenable to solving via coverage-guided property-based testing.


%% In this paper, we follow a two-step procedure to address this challenge:
%% \begin{itemize}
%% \item[{\bf Step 1}] We start from the code hints provided as Javadoc comments, and use
%%   type guidance to seed a components library to be used during Step 2. 

%% \item[{\bf Step 2}] Based on the components library built during the first step, we use program synthesis to find a refactoring that is semantically equivalent to the original code.
%% \end{itemize}

%% syntax and semantics based approach based on program
%% synthesis.  Essentially, we make use of syntactic information from the
%% original code as well as the Javadoc comments to seed a components
%% library, which is then used by a program synthesis engine.
%% Notably, the synthesiser automatically generates refactorings
%% that are guaranteed to be semantically equivalent to the original
%% code.  With respect to the actual program synthesis technique, we use
%% a coverage-based, type and example guided synthesis.


%% fully semantic refactoring approach for removing deprecated elements.
%% There is a very broad space of methods that are able to reason about
%% program semantics.  The desire to perform refactorings safely suggests
%% the use of techniques that overapproximate program behaviours.  As one
%% possible embodiment of semantics-driven refactoring, we leverage
%% software verification technologies with the goal of reliably
%% automating refactoring decisions based on program semantics.
%% Our research
%% hypothesis is that semantics-driven refactorings are more precise and
%% can handle more complex code scenarios in comparison with
%% syntax-driven refactorings.

%% \todo{revise the next two paragraphs}
%% \paragraph{Goal of the paper} 
%% Our goal in this paper is to design a fully automated refactoring
%% technique for eliminating deprecated fields, methods and classes. Our
%% technique will make use of Java library comments to find components
%% for seeding the refactoring. Then, it will use program synthesis to
%% generate code that is semantically equivalent to the original but does not use
%% the deprecated elements.

%% One interesting aspect when using a fully semantics-driven approach is
%% that it allows introducing the notion of {\em refactoring context}.
%% The refactoring context is the context (of the code to be refactored)
%% taken into consideration when looking for a refactoring. Varying the
%% context enables the user to control the generality of the refactoring.
%% \todo{Are we going to cover context?}

%
%% For illustration, for the refactoring in Figure~\ref{ex:deprecated-method-other}...
%% \todo{hmm, what context do we consider for the standard library?}
%
%\todo{Should we also discuss our choice of synthesis in the intro?}

%% In this paper, we are interested in refactoring Java code handing
%% collections through external iteration to use streams. Our refactoring
%% procedure is based on the program semantics and makes use of program
%% synthesis.

\paragraph{Contributions:}

\begin{itemize}

\item We propose a program synthesis based technique for refactoring uses of deprecated APIs, which incorporates semantic information about the code. In particular, the program synthesis is guided by code hints and type information.

\item We encode both the synthesis of refactoring candidates and their verification as program safety problems that we then solve with coverage-guided property-based testing.

  %% propose a program synthesis technique that is driven by type information and code hints, and relies on coverage-guided property-based testing.
  
%\item We provide a technique for building the component library that is guided by code hints and types.
  
%\item We propose greybox program synthesis by encoding the code generation problem as a verification problem that can be solved by coverage-guided property-based testing.
  %% introduce the notion of coverage based CEGIS, which makes use of coverage-guided property-based testing in order to generate counterexamples for a type and example guided synthesiser.
  
%% \item We provide an encoding of the synthesis problem as the problem of verifying the safety of a program, which is then solved by fuzzing.

%% \item We introduce the concept of refactoring context. %% The refactoring context is different from the
%%   %% actual code to be refactored.
%%   Our refactoring technique generally starts 
%%   with no context and gradually increase the amount of context we take into consideration
%%   until a desirable refactoring is found.

\item We implemented our technique in the tool ?? and used it to refactor the methods deprecated in jdk15.
  %refactor deprecated instances in X open source projects.
  
\end{itemize}  

%
%% \begin{itemize}
%% %
%% \item We present a program synthesis based refactoring procedure for Java
%% code that handles collections through external loop iteration.
%% %
%% \item We have implemented our refactoring method in the tool \tool. Our
%% experimental results support our conjecture that semantics-driven
%% refactorings are more precise and can handle more complex code scenarios
%% than syntax-driven refactorings.
%% %
%% \end{itemize}



\section{Overview of our approach} \label{sec:overview}

As mentioned in Section~\ref{sec:intro}, our approach employs program synthesis
in order to generate a refactoring that
%is semantically equivalent to
preserves the behaviour of the original code and
does not use deprecated APIs.
At a high level, the new code is obtained by composing methods
that are accessible from that respective location. 
Consequently, we take inspiration from component-based program synthesis,
which weaves together components from a library
(typically methods from an API) in order to generate the desired program \cite{DBLP:conf/icse/JhaGST10,DBLP:conf/pldi/GulwaniJTV11,DBLP:conf/popl/FengM0DR17}.
%Component-based program synthesis allows us to 

%% While powerful, program synthesis is very hard due to the vast
%% search space. In particular,
For component-based synthesis, real-world
APIs can quickly lead to very large component libraries. %, making synthesis infeasible.
For illustration, in our setting, indiscriminately adding all members
found in \texttt{java.lang} would make synthesis infeasible. % (see experimental results in Section~\ref{sec:experimental-results}).
%% In general program synthesis is very difficult. One of the main
%% challenges is the very large search space.
%% The objective of recent
%% program synthesis research has been to reduce the search space.
%% One such direction, component-based program synthesis allows
%% synthesis techniques to weave together components from a library
%% (typically methods from an API) in order to generate the desired program.
%% While this does improve the efficiency of program synthesis by providing
%% higher order building blocks that can be used..., real-world APIs are still
%% too big.
%
Previous works have used type information to make components-based synthesis
feasible in the presence of large component
libraries~\cite{DBLP:conf/popl/FengM0DR17}.  However, as shown by our
experimental results in
Section~\ref{sec:experimental-results}, the use of types in our setting is still insufficient
for obtaining an efficient refactoring technique.
%that is able to
%provide hints to the developer on-the-fly.
%
%% For related work:
%% However, that worked well when the generated code
%% only had to be type sound and obey at most three test cases. However, in our case
%% we need to generate code that is observationally equivalent to the original.
%% While we will use coverage-guided testing to check observational equivalence (as discussed later),
%% we still check at least 400 inputs. 
%
Our solution is to use the code hints provided in the Javadoc comments to guide the building of the component library. For our running example in Figure~\ref{ex:deprecated-method-other}, the source code for the \texttt{getHours} method in class \texttt{Date} is accompanied by the comment in Figure~\ref{ex:code-hints}, where the \texttt{@code} tag suggests replacing the deprecated \texttt{getHours}
with \texttt{Calendar.get(Calendar.HOUR\_OF\_DAY)}.


\begin{figure}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
/*
 * @return  the hour represented by this date.
 * @see     java.util.Calendar
 * @deprecated As of JDK version 1.1,
 * replaced by {@code Calendar.get(Calendar.HOUR_OF_DAY)}.
 */  
\end{lstlisting}
\caption{Code hints for the running example.}
\label{ex:code-hints}
\end{figure}


%While it might seem that this hint ma solve the entire problem, 
Note that this hint is not immediately usable. Some of the challenges
for this example are:

{\bf Challenge 1.}  Although it may seem as if
method \texttt{get} is static allowing us to make an immediate call,
it is actually an instance method, requiring us to have an object of
class \texttt{Calendar}. However, no such object is available in the
original code meaning that it must be created by the refactored code.
Consequently, we must populate the component library with the necessary
components to create such an object by consuming existing objects.

{\bf Challenge 2.} Besides adding components that allow
us to generate the required objects, we also need
components for setting their fields. For instance,
in Figure~\ref{ex:deprecated-method-other}, we must call
\texttt{calendar.setTime(date)} to set the calendar's date
based on the existing \texttt{date} object.

{\bf Challenge 3.} Adding too many components to the library will
make the synthesis task unfeasible. In particular, we should
be able to differentiate between components that we can use
(we have or we are able to generate
all the necessary arguments and the current object for calling them), and those
that we can't because we can't obtain some of the arguments
and/or the current object. Adding the latter components to the library will
significantly slow down the synthesis process by
adding infeasible programs to the search space.


In Section~\ref{sec:components-seeding}, we provide in-depth details about the
seeding of the component library and how to tackle the above challenges. 
At a high level, the process is guided by types and code hints.

Once the component library is built, for the actual synthesis,
we use a counterexample-guided iterative process that enables us
to keep refining a candidate refactoring until we are happy with it.
The refinement is based on the results provided by 
coverage-guided property-based testing~\cite{DBLP:conf/issta/PadhyeLS19}.
%% Intuitively, we wanted to avoid the overheads due to program analysis and
%% constraint solving incurred by whitebox methods, while also making use of
%% knowledge about the code that can be obtained through lightweight instrumentation.
%% For this purpose, %% we phrased the synthesis problem in a manner that makes it amenable
%% %% to solving via coverage-guided testing. Essentially,
%% we employ an iterative synthesis process based on CounterExample Guided Synthesis (CEGIS)~\ref{},
%% where the problems posed in each iteration are phrased such that they can be solved
%% by coverage-guided property-based testing.
We provide more details about %
the synthesis process in Section~\ref{sec:encoding}.

%% Whitebox approaches can be inefficient as they require fully interpreting the
%% internal structures of the code through some form of static analysis.

%% In this section, we use the example in
%% Figure~\ref{ex:deprecated-method-other} to informally illustrate our
%% technique.  Firstly, our synthesis method is component based, meaning
%% that it uses components from a given library to generate new code.  We
%% use a type-directed method for generating a specifically designed
%% component library for each refactoring. We will provide more details
%% on how to generate the component library in
%% Section~\ref{sec:components-seeding}.  In the current section, we will
%% just assume the component library containts all the instructions
%% necessary to generate the refactoring in
%% Figure~\ref{ex:deprecated-method-other}.

%% Similar to CEGIS, our synthesis process is iterative such that in each
%% iteration an inductive synthesiser generates a candidate refactoring
%% that is subsequently checked by a verifier.  
%% In general, each CEGIS
%% verification phase produces {\em one} counterexample that is added to
%% the set of inputs used by the subsequent synthesis iteration to
%% generate a better candidate.  The implicit assumption is that these
%% inputs are somehow important such that generating a candidate that
%% works for them will help efficiently prune the search space and avoid
%% enumerating all possible programs.

%% In this paper, we propose using the notion of coverage in order to
%% generate counterexamples to be added to the inputs set. Basically, in
%% each iteration of the synthesis process, the verifier will generate
%% multiple counterexample inputs that cause the current candidate to fail the property of interest by
%% exercising different paths.
%% %
%% As we generate refactorings, the property that we are interested to check is observational equivalence
%% with respect to the original code, i.e. for each input, the refactoring must generate the
%% same result as the original code (in reality, as we must handle code with side effects,
%% the refactored and original codes must generate the same program state). 

%% For our running example, the synthesiser generates the following candidate
%% refactoring in the first synthesis iteration:
 
%% \begin{lstlisting}[mathescape=true,showstringspaces=false]
%% void main(String[] args) {
%%   int hour = java.util.Calendar.getInstance().
%%              get(java.util.Calendar.HOUR_OF_DAY);
%% }
%% \end{lstlisting}

%% Compared to the original program in Figure~\ref{ex:deprecated-method-other}, this
%% candidate refactoring is not semantically equivalent as it does not make
%% use of the initial \texttt{date} variable. When passed to the verifier,
%% we obtain X counterexamples, each exercising a different path through the
%% candidate refactoring (note that, while these paths are not visible in the
%% code above, they come from the methods being called). With all these counterexamples,
%% the correct refactoring is found in the second iteration.

%% Our conjecture is that coverage-guided counterexamples help prune
%% the search space during CEGIS. In the experimental evaluation, we will
%% empirically evaluate our conjecture.

%%==========

%% Our technique relies on both syntax and semantics and makes use of advances in the
%% field of program synthesis. In particular, we make use of the general
%% structure of Counterexample Guided Inductive Synthesis (CEGIS), but
%% instead of using symbolic execution to both generate and verify
%% candidate refactorings, we use fuzzing, as described later in this
%% section.  Our synthesis method is also component based, meaning that
%% it uses components from a given library to generate new code.  In the
%% rest of this section, we describe how we build the components library
%% followed by presenting the actual refactoring synthesis.
%%Our technique for refactoring deprecated instances (e.g. fields, methods, classes) has two big steps, as described next.

%% \subsection{{\bf Input to our method}}
%% We expect as input the original deprecated code \var{Orig} with inputs
%% $\vec{x}$, as well as access to the library where the
%% field/method/class has been deprecated. We need the latter to seed the
%% components library.  Depending on the user's intention we may also
%% take into consideration some amount of context (of the location where
%% the deprecated element is found) when searching for a refactoring.

\section{{\bf Seeding of the component library}}\label{sec:components-seeding}
% Our synthesis engine is component based, meaning that, in order to generate new code, it makes use of a library of components.
As mentioned in Section~\ref{sec:overview}, a critical aspect of our technique is the construction
of the component library. 
%For each required refactoring, we start by building the components library.
%This step is critical as
%% the size of the component library has a direct impact
%% on the size of the search space for the respective refactoring.
If the component library is too small, meaning that it doesn't contain all
the required components, then synthesis will fail to find a refactoring.
Similarly, if it contains too many components, then synthesis quickly becomes infeasible
due to the large search space.

Consequently, in our approach, the component library is dynamically built for each refactoring,
such that it only contains components specific to that particular use case.
We designed two versions of the library, differentiated by the seeding guidance:
\begin{itemize}
\item For the {\bf CodeHints-library} the seeding is guided
  by both Javadoc code hints and types.
\item For the {\bf Types-library} the seeding is only guided by types.
\end{itemize}  
%% two versions of the component library
%% To further increase our chances of finding a refactoring fast, we start with a restricted {\em core library} (see Section~\ref{sec:core-library}).
%% If we fail to find a refactoring within a given amount of time, we then increase the size of the library by adding additional components (see Section~\ref{sec:extend-library}).


\subsection{CodeHints-library} \label{sec:core-library}
%As mentioned before, we make use of type and code hints to seed the component library.
In our running example in Figure~\ref{ex:deprecated-method-other}, we can view \texttt{date} of type \texttt{Date} as the input to the code to be refactored, and the integer \texttt{hour} as the output. Generally speaking, the refactoring technique will weave together components from the component library that consume the inputs and generate the required outputs.

Throughout the seeding process, we keep track of the following sets:
$consumable\_ objs$ (inputs to the code to be refactored, which need to be consumed by the refactoring),  
$available\_types$ (types for which we either have consumable objects or the corresponding generators to create them) and 
$target\_types$ (types for which we must be able to generate objects). To start with, the $target\_types$ set
contains the types of the original code's outputs. %, as well as the types of the code hints' arguments (required in order to make use of the code hints).
%(objects directly generated by the code hints or objects created by the generators added to make the code hints realisable)

For the running example, we start with:
%considering the hints are given in Figure~\ref{ex:code-hints} after the
%\texttt{@code} tag., at the beginning of the seeding algorithm, we have:
%For the running example, after initialising the component library with the code hints, we have:
\[
\begin{aligned}
  consumable\_objs &=  \{\texttt{date}\}\\  
  available\_types &=  \{\texttt{Date}\}\\
  target\_types &= \{\texttt{int}\}
\end{aligned}
\]

%% the library seeding algorithm must add components that are able to consume the
%% inputs to the deprecated code and produce the objects required to make use
%% of the Javadoc hints.
%

%From a type-guided perspective,
The objective of the seeding algorithm is to
add components to the library that make use of the $available\_types$ to generate objects
of $target\_types$. At the same time, we want to consume the objects from the
$consumable\_objs$ set, i.e. the inputs of the original code.

The seeding algorithm for the CodeHints-library is provided in Figure~\ref{alg:seeding-core} and consists of three phases, which we discuss next.

\paragraph{{\bf Phase 1: Initialise with code hints}}
During the first phase, the initialisation, we add all the constants and instructions from the code hints to the library.
%
%% Intuitively, the Javadoc code hints should help with that, so we start by adding the
%% suggested instructions to the component library.
For our running example, the hints in Figure~\ref{ex:code-hints} %% after the
%% \texttt{@code} tag.
%% These hints
instruct us to add method \texttt{``int get(int field)''} from class
\texttt{Calendar} and constant \texttt{``Calendar.HOUR\_OF\_DAY''} to our library.
%For the core library, we actually fix the \texttt{``Calendar.HOUR\_OF\_DAY''} constant
%in place, thus adding \texttt{``int get(Calendar.HOUR\_OF\_DAY)''}.
As a side note, finding the right constants is a well known
challenge for program synthesis~\cite{DBLP:conf/cav/AbateDKKP18}, and thus the subsequent
synthesis process will always attempt to use the constants provided in the code hints before generating new ones.

Intuitively, we need to make sure that the Javadoc suggestions
are realisable as captured by Definition~\ref{def:realizable}, where 
%We formally refer to such a component as {\em realisable} as captured by Definition~\ref{def:realizable}, where
%$source\_types$ to refer to types for which we have the means to generate objects, and
$required\_types(method)$ refers to the types of the objects required to call $method$ (i.e. the types corresponding to its arguments and current object).
%for $instr$ to be realisable.
In our running example, $required\_types(\texttt{get}) = \{\texttt{int, Calendar}\}$
given that, in order to call \texttt{get}, we must provide an argument of type \texttt{int} and a current object of type \texttt{Calendar}.
Method \texttt{get} is not realisable as the library doesn't contain any generator for \texttt{Calendar}.
Consequently, \texttt{Calendar} is added to $target\_types$, resulting in $target\_types = \{\texttt{int, Calendar}\}$

%% at the beginning of the library seeding process:
%% \[
%% \begin{aligned}
%%   source\_types &=  \{\texttt{Date}\}\\
%%   required\_types(\texttt{get}) &= \{\texttt{int, Calendar}\}
%% \end{aligned}
%% \]
%% where the required types for component \texttt{get} to be realizable
%% are \texttt{int} and \texttt{Calendar} because, in order to call \texttt{get}, we must provide an argument of type \texttt{int} and a current object of type \texttt{Calendar}. With respect to
%% the source types, we have the object \texttt{date} of type \texttt{Date}, which
%% our refactoring can consume.
%% As for the core library,
%% we fix the argument \texttt{``Calendar.HOUR\_OF\_DAY''}, we actually have $required\_types(get) = \{Calendar\}$.


%% We call such an instruction {\em realizable}, according to Definition~\ref{def:realizable}.
%% In the definition, we use
%% \var{required\_types(i)} to denote
%% the set of the types of the parameters and receiver required to call instruction \var{i}.

\begin{definition}[Realisable method]\label{def:realizable}
Method \var{i} is {\em realisable} iff $\forall t \in required\_types(i). t \in available\_types \vee t~is~a~primitive~type$.
\end{definition}

For our running example, \texttt{Calendar} is needed
in order to call method \texttt{get}, which is required by the code hint. However, our library doesn't contain any way of creating such an object.
Then, we add \texttt{Calendar} to $target\_types$.

%% The objective is to generate objects for the $target\_types$, while consuming objects from $consumable\_objs$.
%% During the process, $available\_types$ tells us for which types we have the means
%% of generating objects.

\paragraph{{\bf Phase 2: Add generators for $target\_types$}}

%When referring to the algorithm in Figure~\ref{alg:seeding-core}, 
%In the second phase of the seeding algorithm, 

%In the algorithm in Figure~\ref{alg:seeding-core}, %% in the second phase, we add ways of generating
%% objects whose types match the types of the required arguments and current objects to the library.
%
By generators, we refer to constructors and any other methods returning objects of that particular type.
%% Essentially, for each required type that we have no way of generating, we add all the realizable
%% constructors and realizable methods returning objects of that type to the
%% core library.
Once we added a generator for a new type, we must add that type to $available\_types$.
Additionally, if the new generator consumes any objects from $consumable\_objs$,
we must remove them from the set.
%More details on this in Section~\ref{sec:synthesis}.

For our running example, we must seed our component library with generators for \texttt{Calendar}.
%
We first scan all the public constructors of class \texttt{Calendar}
and all the public methods from class \texttt{Calendar} that return an object of type \texttt{Calendar}. We find the following four options:

\begin{enumerate}
  \item \texttt{static Calendar	getInstance()} -- creates a \texttt{Calendar} object using the default time zone and locale.
  \item \texttt{static Calendar getInstance(Locale aLocale)} -- creates a \texttt{Calendar} object using the default time zone and specified locale.
  \item \texttt{static Calendar	getInstance(TimeZone zone)} -- creates a \texttt{Calendar} object using the specified time zone and default locale.
  \item \texttt{static Calendar	getInstance(TimeZone zone, Locale aLocale)} -- creates a \texttt{Calendar} object with the specified time zone and locale.
\end{enumerate}

%% For our illustrating example, the only object used by the deprecated code is \texttt{Source\_Obj}=\{\texttt{date}\} with given type \texttt{Source\_Type}=\{\texttt{Date}\}. Using these, we need to obtain an object of type \texttt{Target\_Type}=\{\texttt{Calendar}\}, so that we can make use of the JavaDoc hint.  
%
%Out of the four options above, we are interested in those for which we have the means to generate all their arguments and the current object. 
Out of the four methods,
%from our example that can produce objects of type \texttt{Calendar},
only the first one is realisable. Conversely, in order to call the second method, we would need to generate an object of type \texttt{Locale},
for which we don't have a corresponding component in the library.
The last two methods are in a similar situation as the second. Thus, we only add the first method to the CodeHints-library.

%% Even though we add them, they are not going to be used by the synthesis engine
%% as we use a type-directed approach to term generation...



%(those from the code hints are fixed in place).
%% Then, we also add all the instructions contained
%% in the code hints.

\paragraph{{\bf Phase 3: Add mutators for $target\_types$}}
The third and last phase adds  mutators for the target types.
By mutators we refer to methods that modify the value of an instance variable.
Given our objective to generate objects for the $target\_types$ while consuming objects from $consumable\_objs$,
we prioritise mutators that consume such objects.
For instance, for our running example there are 16 public mutators for the \texttt{Calendar} class.
However, for the CodeHints-library, instead of adding all of them, we prioritise those that
consume the \texttt{date} object. There is only one such mutator \texttt{void setTime(Date date)}.
Once we added any new mutators to the library, we remove the consumed objects from \texttt{consumable\_obj}.

%% Besides ways of generating objects of certain types, we also need to be able to
%% modify the newly generated objects by setting their fields.
%% This is covered in the algorithm given in Figure~\ref{alg:seeding-core}
%% by adding $modifiers$ to the library.
%% For the running example, the modifiers that we add to the library are
%% ...

%% Once we added the components required to generate an object of a given type,
%% we add that type to $source\_types$.
Notably, all the components that
we add to the library must be accessible from the current location.

%% we overload \var{ensured\_types} to take \var{library} as an argument, in which case it returns the set of all the types of the objects that can be created using the instructions in the library.

%% In certain situations, the seeding of the component library may require additional work.
%% For instance, for the example in Figure~\ref{ex:deprecated-method-other}, we need to also provide a way of obtaining
%% a \texttt{Calendar} object. Thus, we add \texttt{Calendar.getInstance()}. 

%% \SetKwInOut{KwIn}{Input}
%% \SetKwInOut{KwOut}{Output}

%% \begin{figure}
%% \removelatexerror% Nullify \@latex@error
%% \begin{algorithm}[H]
%% \SetAlgoLined
%% \KwOut{Core component library}
%%  Add constants from the code hints and the original code\;
%%  Add instructions from the code hints\;
%%  \For{instr $\in$ library}{
%%    \If{$\neg$realizable(instr)}{
%%      \For{$type {\in} required\_types(instr) ~\&\&~ type {\not\in} source\_types$}{
%%        $generators = realizable\_constructors(type) \cup realizable\_methods\_returning\_type(type)$\;
%%        $modifiers = realizable\_methods\_with\_receiver\_of\_type(type)$\;
%%        Add $generators$ to the library\;
%%        Add $modifiers$ to the library\;
%%        \If{$generators \neq \emptyset$}{$source\_types = source\_types \cup\{type\} $}
%%      }
%%    }
%%  }
%% \end{algorithm}
%%  \caption{Seeding algorithm for the core library}
%% \label{alg:seeding-core}
%% \end{figure}


\begin{figure}
\removelatexerror% Nullify \@latex@error
\begin{algorithm}[H]
\SetAlgoLined
\KwOut{CodeHints-library}
%<<<<<<< HEAD
// {\bf Phase 1: Initialise}\\
Add constants and instructions from the code hints\;
\For{each unrealisable instruction $i$ in library}{
  $target\_types$ = $target\_types \cup required\_types(i)$\;
}

// {\bf Phase 2: Add generators for $target\_types$}\\
\For{each $t \in target\_types$ for which there is no generator}{
  Add realisable generators for $t$ to library\;
  $available\_types = available\_types \cup \{t\}$\;
  Remove consumed objs from $consumable\_objs$\;
}

// {\bf Phase 3: Add mutators for $target\_types$}\\
\While{$consumable\_obj\neq\emptyset$}{
Add realisable mutators to the library for types in $target\_types$ that consume objects from $consumable\_objs$\;
Remove consumed objs from $consumable\_objs$\;
}
%% =======
%%  Add constants from the original code to the library\;
%%  Add instructions from the code hints to the library\;
%%  \For{instr $\in$ library}{
%%    \If{$\neg$realizable(instr)}{
%%      \For{$type {\in} required\_types(instr) ~\wedge~ type {\not\in} source\_types$}{
%%        $generators = realizable\_constructors(type) \cup realizable\_methods\_returning\_type(type)$\;
%%        $modifiers = realizable\_methods\_with\_receiver\_of\_type(type)$\;
%%        Add $generators$ to the library\;
%%        Add $\mathit{modifiers}$ to the library\;
%%        \If{$generators \neq \emptyset$}{$source\_types = source\_types \cup\{type\} $}
%%      }
%%    }
%%  }
%% >>>>>>> 64d053e021f0976d2f4411950ad48f41ed31c8d9
\end{algorithm}
 \caption{Seeding algorithm for the CodeHints-library}
\label{alg:seeding-core}
\end{figure}

It may be the case that there is no realisable generator for a target type, or no mutators for the $target\_types$ that can consume all the
$consumable\_objs$. When we finish exploring all the available methods, we exit the corresponding loops in phases 2 and 3.
As a consequence, the synthesiser may fail to generate a valid refactoring when relying solely on the CodeHints-library.
%% For such a situation, we extend the component library as explained in Section~\ref{sec:extend-library}.
A possible future direction is allowing unrealisable generators and mutators to be added to the library and iterating phases 2 and 3 a given number of times (potentially until fixed point).
%% iterate phase 2 and 3 until fixed point to 

\subsection{Types-library} \label{sec:extend-library}

For the CodeHints-library, the Javadoc code hints guidance results in the code hints being
used to collect the $target\_types$ set during the initialisation phase.
Conversely, when seeding solely based on types, we start with the $target\_types$ set containing
the class where the original code resides, as well as the type of the inputs and outputs of the
original code. Phases 2 and 3 of the seeding algorithm are the same as those in Figure~\ref{alg:seeding-core},
i.e. we attempt to add generators and mutators for the $target\_types$ to the library.

%For our running example, we would have $target\_types = \{\}$

While we expect some overlap between the Types-library and the CodeHints-library, 
the former may miss critical types provided by the Javadoc code hints.
For instance, in our running example, the \texttt{Calendar} class is only mentioned by the
code hints and would not be included in the Types-library.

%% it's otherwise impossible to obtain, while trying to
%% keep the component libraries relatively small.

%% We use the Types-library if the synthesis fails for the CodeHints-library, or if
%% we fail to find or parse the Javadoc code hints. 


%\todo{Discuss what happens if no hint exists or it can't be parsed.}

%% If the synthesis engine fails to find a refactoring within a certain amount of time,
%% there might be a need to extend the components library.
%% For the core library, in the algorithm in Figure~\ref{alg:seeding-core}, we only ever add realizable components. However, this requirement can be relaxed by adding components that
%% are not yet realizable, but would become so if we were to add one
%% additional instruction (the generator for the missing type). For our current experiments,
%% there was no need to expand the core library. \todo{check this.}

%% we start to incrementally increase the size of the library by adding additional components to be used during synthesis.
%% The library expansion algorithm is provided in Figure~\ref{alg:seeding-extended}.
%% Essentially, we go through all the instructions in the current library and add
%% ways of generating objects that can be used as their arguments (i.e. whose types match that of their arguments).
%% Note that, as opposed to the core library, here we look at all instructions, not just the realizable ones.


%%\begin{figure}
%% \begin{algorithm}[H]
%% \SetAlgoLined
%% \KwIn{Current library}
%% \KwOut{Expanded component library}
%%  \For{instr $\in$ library}{
%%      \For{$type {\in} required\_types(instr)$}{
%%        $generators = realizable\_public\_constructors(type) \cup realizable\_public\_methods\_returning\_object\_of\_type(type)$\;
%%        Add $generators$ to the library\;
%%      }
%%  }
%% \end{algorithm}
%% \caption{Incremental expansion of the component library}
%%\label{alg:seeding-extended}
%%\end{figure}

%% As future work we aim to also collect components and sketches from the  unit tests for the updated library.
 
\section{Synthesising the refactoring}\label{sec:encoding}

We make use of a CounterExample Guided Inductive Synthesis (CEGIS)~\cite{DBLP:conf/pldi/Solar-LezamaJB08} architecture, where we
iteratively improve a candidate refactoring (generated using the component library) until it obeys a given specification.
In our case, the specification expresses the fact that the original and
the refactored blocks of code need to have the same behaviour, meaning that they are observationally equivalent.
%
In the rest of the paper, we will use the predicate
$equivalent(P_1(\vec{i}), P_2(\vec{i}))$ to denote that code $P_1$ is
observationally equivalent to $P_2$ for inputs $\vec{i}$.  In general,
we refer to the original code as $P_1$ and the refactored code as
$P_2$. We will fully define what $equivalent$ actually means in Section~\ref{sec:equiv}.


In each iteration of the synthesis process, there are two phases, a synthesis and a verification one. We next show how we encode the problem corresponding to each of these phases so that it can be solved with fuzz testing. 
% As we want to start with a high level view

\paragraph{The synthesis phase} In this phase, we have 
a finite set of input examples $\{\vec{i_1} \cdots \vec{i_n}\}$ and we must find a candidate refactoring
that is observationally equivalent to the original code for the given inputs.
For this purpose, we construct the following \texttt{Synthesise} method, which
takes the refactored code $P_2$ as input.

\begin{lstlisting}[mathescape=true,showstringspaces=false]
Synthesise ($P_2$) {

  if (equivalent($P_1$($\vec{i_1}$), $P_2$($\vec{i_1}$)) && ...
      && equivalent($P_1$($\vec{i_n}$), $P_2$($\vec{i_n}$)))
    assert(false);
}
\end{lstlisting}

This method consists of only one conditional saying that if $P_1$ and $P_2$ are equivalent on all given inputs $\vec{i_1}, \cdots, \vec{i_n}$, then \texttt{assert(false)} is reached.
Given that this assertion always fails, it means that the method is unsafe when $P_1$ and $P_2$ are equivalent on the given inputs.
Thus, we can reduce the synthesis problem to the problem of checking the safety of \texttt{Synthesise}. If a safety checker manages to
find an input $P_2$ for which the assertion fails (meaning that \texttt{Synthesise} is unsafe), then this $P_2$ must be equivalent to $P_1$ on the given inputs. This $P_2$ is the code
that the synthesis phase is supposed to generate. As aforementioned, we use an existing fuzz testing technique
as the safety checker. We configure the fuzzer such that it constructs $P_2$ by weaving together components from the component library.

If the safety checker fails to find a $P_2$ for which the assertion fails, then the overall synthesis technique fails to generate a solution refactoring.
There could be two reasons for this situation, which we cannot differentiate between.
Firstly, there may indeed be no $P_2$ that can be constructed with the available components in the component library such that
it is equivalent to $P_1$ on the given inputs. Secondly, this could be caused by the fuzzer's unsoundness.
Given that fuzzers rely on testing, they may fail to find inputs that trigger unsafe behaviours even when such inputs exist.
Consequently, we cannot guarantee that we will always find a refactoring whenever one exists. We will provide more details about our decision to use fuzzing as the safety checker in 
Section~\ref{sec:fuzzing}.

%% In other words, answering the initial question posed by the
%% synthesis phase is now reduced to checking the safety of the \texttt{Synthesise} method.
%% If the method is unsafe meaning that the assertion is reached and failed (if reached, the assertion \texttt{assert(false)} always fails)

%% Again, we reduce the problem to be solved in the synthesis phase to
%% the problem of checking the safety of the \texttt{Synthesise} method,
%% which we do by fuzzing.
%% The fuzzer will find an input \var{Candidate} that fails the assertion,
%% meaning that it returns the same output as \texttt{Orig}
%% on the finite set of inputs \var{x_1, \cdots, x_n}.


%% iterative process that enables us to keep refining a candidate refactoring until we are happy with it. This process consists of two phases, described next:
%%   \begin{itemize}
%%   \item[{\bf Phase 1:}] Given a fixed set of inputs $In$, find a refactoring that works for $In$. For this purpose, we encode   
%%     the synthesis problem as a verification problem that can be solved by fuzzing. We discuss this problem encoding in
%%     Section~\ref{sec:encoding}. The found refactoring is called a candidate.
%%   \item[{\bf Phase 2:}] Given the candidate synthesised at the previous step, verify whether it is indeed a correct refactoring.
%%     Again, we answer this question by encoding it as a software verification problem to be solved by fuzzing (see Section~\ref{sec:encoding}).
%%     If an input for which the candidate isn't observationally equivalent to the original code is found, then
%%     we return to the previous step and add this input to the set $In$. Otherwise we have found a correct refactoring and we are done.
%%   \end{itemize}


\paragraph{The verification phase} For the verification phase, we are provided with a candidate
refactoring $P_2$ and we must check whether there exists any input
$\vec{i}$ for which the original code and the candidate
refactoring are not observationally equivalent.  To do this, we build
the following \texttt{Verify} method, which given some input
$\vec{i}$, asserts that the two programs are equivalent for
$\vec{i}$.

\begin{lstlisting}[mathescape=true,showstringspaces=false]
Verify($\vec{i}$) {
  assert(equivalent($P_1(\vec{i})$, $P_2(\vec{i})$));
}
\end{lstlisting}

In other words, answering the initial question posed by the verification
phase is reduced to checking the safety of this method: if
\texttt{Verify} is safe (i.e. the assertion is not violated) for any
input~$\vec{i}$, then there is no input that can distinguish
between the original and the candidate refactoring (this
is indeed a sound refactoring). However, if \texttt{Verify} is not safe,
then we want to be able to obtain a counterexample input
$\vec{i_{cex}}$ for which the assertion fails.

This counterexample will be provided back to the synthesis phase and
used to refine the current candidate refactoring. Again, we check the
safety of \texttt{Verify} with fuzz testing,
which means that we may fail to find a distinguishing input when one
does exist.


%% notion of program equivalence.  While this is undecidable in
%% general, our synthesis procedure in the verification phase this problem is restricted to
%% checking that \var{Orig} and \var{Candidate} are equivalent for a .


%% The fuzzer will find an input for which the original and refactored code
%% produce a different result.



%% - Performing the synthesis. Complex bit: synthesising method invocations for methods that contain loops.

%% \begin{enumerate}
%% \item We seed the templates/snippets for the synthesis library using the following two strategies:
%%   \begin{itemize}
%% \item Use deprecated block messages.
%% \item Use the unit tests for the new library. As opposed to the comments in libraries,
%%   the unit tests are syntactically valid.
%%   \end{itemize}

%% \item Use the seeded templates to generate the refactoring.
%%   \begin{itemize}
%% \item Look at checking equivalence in the presence of loops.
%%   \end{itemize}
%%   \end{enumerate}

\subsection{Checking program equivalence for a certain input}\label{sec:equiv}

A core part of the synthesis procedure is the $equivalent(P_1(\vec{i}), P_2(\vec{i}))$ predicate,
which checks that the original code $P_1$ and a candidate refactoring $P_2$
are equivalent for a given input $\vec{i}$.
%% Naively, this would be checked by comparing the results returned by the
%% \var{Orig} and \var{Candidate}. However, that is not enough as
%% we must also consider the heap representation. We will discuss this in
%% Section~\ref{sec:equiv}.
%% In Section~\ref{sec:encoding}, we use \var{equivalent(Orig(x),
%%   Candidate(x))} to denote equivalence checking for \var{Orig} and
%% \var{Candidate} on concrete input \var{x}.
In this section, we provide details on how we check this equivalence.


%% First, this function needs
%% to check whether for input \var{x}, the outputs of the original and
%% candidate refactored programs are the same.  Moreover, any realistic
%% Java program makes modifications to the heap. Consequently,
%% \var{equivalent} must check that heap is being handled in the same
%% manner in both programs.


We start by introducing some notation:
\begin{itemize}
\item \var{loadedClasses(P)} returns the set of classes loaded by the class loader
  in which \var{P} is executed.
\item \var{liveVars(P)} provides the set of variables that are live
at the end of $P$. %% Thus, \var{liveVars(P_1)} gives us the
%% variables that have been updated in the original code \var{P_1} and are
%% live at the end of \var{P_1}.
\item \var{staticFields(C)} returns
  the set of static fields of a class \var{C}.
\item $exc(P, \vec{i})$ returns the exception thrown by $P$'s execution on input $\vec{i}$.  
\end{itemize}  

\begin{example}\label{ex:defs}
  For our running example in Figure~\ref{ex:deprecated-method-other},
  \var{P_1} and \var{P_2} are represented by the following lines of code. Note that
  both $P_1$ and $P_2$ take variable $date$ as input.

\begin{lstlisting}[mathescape=true,showstringspaces=false]
  // $P_1$:
  int hour = date.getHours();

  // $P_2$:
  final Calendar calendar = Calendar.getInstance();
  calendar.setTime(date);
  int hour = calendar.get(Calendar.HOUR_OF_DAY);
\end{lstlisting}
%
Then, we have:
\[
\begin{aligned}[t]
  \var{liveVars(P_1)} &= \{date, hour\}\\
  \var{liveVars(P_2)} &= \{calendar, date, hour\}\\  
  \var{loadedClasses(P_1)} &= \{Date\} \\
  \var{loadedClasses(P_2)} &= \{Calendar, Date\} \\  
  \var{staticFields(Date)} &= \emptyset\\
  \var{staticFields(Calendar)} &= \{DATE, YEAR, \cdots\}\\
  \var{exc(P_1, \_)}=\var{exc(P_2, \_)} &=\emptyset
\end{aligned}
\]
\end{example}

%Note $exc$ returns $\emptyset$ regardless of the value of $date$.

In order to extract the (last) object assigned to a variable \var{v} by the execution of \var{P} on a specific input $\vec{i}$,
we will use the notation $E[P(\vec{i})](v)$. Essentially, if we consider the trace generated by executing $P(\vec{i})$,
then $E[P(\vec{i})]$ maps each variable defined in \var{P} to the last object assigned to it by this trace.
Next, we define the notion of equivalence with respect to a concrete input $\vec{i}$ (this definition is incomplete and we will build up on it in the rest of the section).

\begin{definition}[Program equivalence with respect to a concrete input $\vec{i}$ {\bf[partial]}]\label{def:prog-equiv}
  Given two code blocks \var{P_1} and \var{P_2} and concrete input~$\vec{i}$,
  we say that \var{P_1} and \var{P_2} are equivalent
  with respect to $\vec{i}$, written as $equivalent(P_1(\vec{i}), P_2(\vec{i}))$
  if and only if the following conditions hold:
%
\[
\begin{aligned}
  & (1) exc(P_1, \vec{i})=\{e_1\} \wedge exc(P_2, \vec{i})=\{e_2\} \wedge equals(e_1,e_2) ~\vee\\
  & \qquad exc(P_1, \vec{i})=exc(P_2, \vec{i}) =\emptyset \\ 
      & (2)~ \forall v\in \var{liveVar}(P_1). \\
      & \qquad v\in \var{liveVar}(P_2) \wedge equals(E[P_1(\vec{i})](v), E[P_2(\vec{i})](v))\\
%& (2) equivalent(aliasEquivClass(liveVar(P_1)), aliasEquivClass(liveVar(P_2)))      
& (3)~  \forall C \in \var{loadedClasses}(P_1). C \in \var{loadedClasses}(P_2)~ \wedge \\
  &  \qquad \forall f {\in} \var{staticFields}(C).equals(E[P_1(\vec{i})](f), E[P_2(\vec{i})](f))
    %%   throws an exception and   $equiv(exception(R_1), exception(R_1))$. 
  %% \item \var{R_1} doesn't throw an exception and $equiv(R_1,R_2)$ and
   %% $\forall f_i \in getStatic(class(R_1)) \wedge g_i \in getStatic(class(R_2)). equiv(f_i,g_i)$.
    \end{aligned}
    \]
   
  \end{definition}

The above definition says that in order for \var{P_1} and
\var{P_2} to be equivalent with respect to input $\vec{i}$,
(1) either they both throw an exception and the two exceptions have the same type, or none does,
(2) any variable
that is live at the end of \var{P_1}, must also be live at the end of \var{P_2}, and  must be
assigned equal objects by the executions of \var{P_1} and
\var{P_2} on $\vec{i}$, respectively, and
(3) for any class that
is being loaded by the class loader of \var{P_1}, it must also be loaded by the class loader of \var{P_2}, and
all its static fields must be assigned equal objects by the
two executions, respectively.  Here, equality refers
to value equality, which We
check by recursively following attribute chains until we reach
primitive types.  We generally do not consider existing \texttt{equals} methods
unless (i)~the method was not written by the user (i.e.  JCL classes),
(ii)~the type inherits from \texttt{java.lang.Object}, (iii)~the class
implements \texttt{java.lang.Comparable} and (iv)~the type declares an
\texttt{equals} implementation.  Examples of classes that satisfy these
strict requirements are \texttt{java.lang.Integer} or
\texttt{java.util.Date}.  All other \texttt{equals} implementations are
considered unreliable and ignored.

%Alternatively, if there is an explicit \texttt{equals} implemented for a given type, then we use it.
%% By equal objects we mean objects where the values of the
%% corresponding attributes are equal.

Regarding the loaded classes, in our implementation, if either the deprecated or the refactored code didn't load a class, we load it for it,
and check that the initial state of that class is the same for both blocks of code.

%% Note that, as mentioned in its name, Definition~\ref{def:prog-equiv} only partially
%% defines the equivalence of \var{P_1} and \var{P_2} on input \var{\vec{x}}. For now
%% we will ignore this and get back to it later in the section.


%In our experiments, given that we only refactor deprecated methods, the only live variable at the end of the original invocation is \var{this}.

\begin{example}\label{ex:equiv}
  When applying Definition~\ref{def:prog-equiv} to \var{P_1} and \var{P_2} given in Example~\ref{ex:defs},
  the following conditions must hold (given that class \var{Date} has no static fields, the third condition is trivial):
\[
\begin{aligned}
      & (1)~ \var{exc(P_1)}=\var{exc(P_2)} =\emptyset\\
      & (2)~ equals(E[P_1(\vec{i})](hour), E[P_2(\vec{i})](hour)) ~ \wedge\\ %date\in \{date,calendar\} ~ \wedge \\
      & \qquad equals(E[P_1(\vec{i})](date), E[P_2(\vec{i})](date))\\
& (3)~  \var{Date} \in \{\var{Date}, \var{Calendar}\}
    %%   throws an exception and   $equiv(exception(R_1), exception(R_1))$. 
  %% \item \var{R_1} doesn't throw an exception and $equiv(R_1,R_2)$ and
   %% $\forall f_i \in getStatic(class(R_1)) \wedge g_i \in getStatic(class(R_2)). equiv(f_i,g_i)$.
    \end{aligned}
    \]

 
    %% Then, in order for the two portions of code to be
    %% equivalent with respect to an input \var{x}, the objects assigned to variable \var{date} by the execution of  \var{P_1(x)} and \var{P_2(x)}
    %% must be equivalent. We will discuss checking equivalence of two objects in two distinct executions next.
    
\end{example}

%%\todo{define $equivalent(E[P_1(x)](v), E[P_2(x)](v))$}.

\paragraph{Preserving aliasing}

When expressing the equivalence relation between \var{P_1} and \var{P_2}, we
intentionally missed one important aspect, namely aliasing.  To understand
the problem let's look a the following example, which makes use of
java.awt.Container, where a generic Abstract Window Toolkit (AWT) container
object is a component that can contain other AWT components.  Method
\texttt{preferredSize} used by the original code below returns the preferred
size of the calling container. Method
\texttt{preferredSize} is deprecated, and, instead, the refactored version
uses \texttt{getPreferredSize}.

%, which denotes a slightly
%modified version of the running example.

\begin{example}\label{ex:aliasing}
~\begin{lstlisting}[mathescape=true,showstringspaces=false]
  // $P_3$:
  Dimension dim1 = container.preferredSize();
  Dimension dim2 = container.preferredSize();    

  // $P_4$:
  Dimension dim1 = container.getpreferredSize();  
  Dimension dim2 = dim1;
\end{lstlisting}
%\end{example}


%\todo{Get another example from Pascal, where the return is an object.}

%% \begin{example}\label{ex:aliasing}
%%   \begin{lstlisting}[mathescape=true,showstringspaces=false]
    
%%   // assume date refers to 2022-12-01 13:30:00    

%%   // $P_3$:
%%   int hour1 = date.getHours();
%%   int hour2 = date.getHours();    

%%   // $P_4$:
%%   final Calendar calendar = Calendar.getInstance();
%%   calendar.setTime(date);
%%   int hour1 = calendar.get(Calendar.HOUR_OF_DAY);
%%   int hour2 = hour1;
%% \end{lstlisting}

%% For the code above, we will refer to the first two lines denoting the
%% original deprecated code as \var{P_3}, and the rest, denoting the
%% refactored code, as \var{P_4}.

We note that, the original code above defines two variables \var{dim1} and
\var{dim2}, each assigned an object of type \texttt{Dimension} returned by calling
\var{container.preferredSize()}.
Conversely, in the refactored code, \var{dim1} and \var{dim2} are aliases, i.e. they point to the same
object of type \texttt{Dimension}.

The original and the refactored code are equivalent according to Definition~\ref{def:prog-equiv}.
Let's next assume that the following code
is used after both the original and the refactored code, respectively.

\begin{lstlisting}[mathescape=true,showstringspaces=false]
  dim1.setSize(1,2);
  dim2.setSize(2,3);  
\end{lstlisting}

%Our intention is to execute both the original and the refactored code, respectively, plus the additional two lines.
If the original and the refactored code were indeed equivalent,
%with respect to input \var{d},
then we would expect \var{dim1} and \var{dim2} to have the same value at the end of both blocks of code. 
%executions, respectively.
However, this is not the case.
In the original code, \var{dim1} will have width 1 and height 2, whereas in the refactored code,
\var{dim1} will have width 2 and height 3. This is due to the fact that,
in the refactored code, \var{dim1} and \var{dim2} are aliases. %% Then, when the object referenced by
%% \var{hour1} was changed to refer to the date denoting ``30/10/2020'', this also affected \var{date2}.
Thus, when \var{dim2} has its size set to (2,3), this also affects \texttt{dim1}.
%\var{P_3} and \var{P_4} are not equivalent for input \var{d}.
\end{example}  

Intuitively, any aliases between live variables at the end of the original code should also
be present at the end of the refactored code. For this purpose, we use the notation
\var{aliasEquivClass(V)} which returns the set of all equivalence classes induced over the
set of variables \var{V} by the aliasing relation.  
Notably, the aliasing equivalence relation must also hold over the
static fields of the classes loaded by both programs.


\begin{example}
For \var{P_1} and \var{P_2}, there are no aliases, therefore:
\[
\begin{aligned}[t]
  \var{aliasEquivClass(liveVar(P_1) \cup staticFields(loadedClasses(P_1))} &= \emptyset\\
  \var{aliasEquivClass(liveVar(P_2) \cup staticFields(loadedClasses(P_2))} &= \emptyset
\end{aligned}
\]
%
However, for \var{P_3} and \var{P_4} we have:
\[
\begin{aligned}[t]
  \var{aliasEquivClass(liveVar(P_3) \cup staticFields(loadedClasses(P_3))} &= \emptyset\\
  \var{aliasEquivClass(liveVar(P_4) \cup staticFields(loadedClasses(P_4))} &= \\
  \qquad \{\{date1, date2\}\} &
\end{aligned}
\]
In \var{P_4}, the alising relation induces one equivalence class, namely \var{\{dim1, dim2\}}.

\end{example}
  
Next, we complete Definition~\ref{def:prog-equiv} by capturing the aliasing aspect.

\begin{definition}[Addition to Definition~\ref{def:prog-equiv}]\label{def:prog-equiv-add}
   In addition to Definition~\ref{def:prog-equiv},
  two programs \var{P_1} and \var{P_2} are equivalent
  with respect to $\vec{i}$ iff:
\[
    \begin{aligned}
      & (4)~ \forall v_1,v_2 \in \mathit{liveVar}(P_1) \cup \mathit{staticFields}(loadedClasses(P_1)). \\
      & \qquad aliases(P_1, v_1, v_2) \Rightarrow aliases(P_2, v_1,v_2)      
    %% & (5)~\forall f_1,f_2 \in staticFields(loadedClasses(P_1)).\\
    %%   & \qquad aliases(P_1, f_1, f_2) \Rightarrow aliases(P_2, f_1,f_2)
    %%   throws an exception and   $equiv(exception(R_1), exception(R_1))$. 
  %% \item \var{R_1} doesn't throw an exception and $equiv(R_1,R_2)$ and
   %% $\forall f_i \in getStatic(class(R_1)) \wedge g_i \in getStatic(class(R_2)). equiv(f_i,g_i)$.
    \end{aligned}
    \]
   
  \end{definition}

where, given a program \var{P}, variables \var{v_1} and \var{v_2} are aliases, i.e. \var{aliases(P, v_1, v_2)} holds,
if and only if they are in the same equivalence class induced by the aliasing relation,\\
  i.e. $aliasEquivClass(\{v_1,v_2\}) = \{\{v_1,v_2\}\}$.

  We abuse the notation to use \var{staticFields} over a set of classes, rather than just one class.
  The objective is to return the union of all static fields defined in all the classes in the set of classes taken as argument.
  

%\todo{also add an example where static fields are changed.}


%% Aliasing check: checks whether the two given objects have the same aliasing ID, and thus
%%    alias with the same objects on their respective heaps.

%%    What do you assign id's to? I'm trying to figure out whether this is too strict?
%%    Basically, equivalence classes induced by the aliasing relation need to be preserved,
%%    but they may not have the same representative ID.

%% You compare execution results:
%% - do you just look at the returned object?

%% Equivalent execution results
%% - returned value
%% - static fields of the corresponding classes

%% Equivalent objects
%% - ObjectIdComparator
%% - IsAliasingEquivalent

%% State: static fields of all classes, stack vars, follow object pointers, thread locals?, equivalence classes induced by the aliasing relation must be preserved
%% - touch the same vars
%% - all touched vars correspond to equivalent objects
%% - 2 graphs are isomorphic

%% 2 obj are equal if all their fields are equal
%% 2 primitive types are equal if they are the same value

%% ============

%% a1 = new Integer(1);
%% b1 = new Integer(1);

%% vs

%% a2 = new Integer(1);
%% b2 = a2;



%% A class is initialized when a symbol in the class is first used. When
%% a class is loaded it is not initialized.


%% Discuss different types of fuzzing and the one that we use.
%% \todo{Double check with Pascal what he uses.}

%% \section{Algorithm}

%% \todo{Write description of the algorithm}

%% \subsection{Reduction of semantically equivalent programs}

%% \subsection{Guarantees} \label{sec:guarantees}

%% \paragraph{Discussion on soundness} Given that we rely on fuzzing, we can't guarantee that the
%% refactoring works for all possible inputs. However, it is well suited
%% to the particular scenarios for which we designed our technique,
%% IDE integration where the refactoring is presented as a suggestion to the programmer,
%% or automated pull requests to be approved by the developers.

%% In order to fully guarantee the soundness of the refactorings proposed
%% by our technique, we would have to use a sound verification technique
%% in the verification phase mentioned earlier. However, such a technique
%% would require symbolic execution, which is notoriously difficult for
%% real-world programs due to features such as loops, library functions,
%% complex data structures. The most successful such verification
%% techniques are either bounded (i.e. check that an erroneous state
%% cannot be reached within a bounded number of loop unrollings) or
%% require user input in the form of loop invariants. While the former
%% class of techniques provides limited soundness guarantees, the latter
%% requires intricate help from the user.  In fact, we are not aware of
%% any sound and automatic symbolic verification method that can handle
%% the kind of code we are interested in.

%% Discuss tradeoff: symbolic execution is expensive; programming
%% languages evolve faster than verification techniques and therefore
%% many new features are not supported by their front ends (and/or
%% backends depending on how complex the new feature is); even after
%% translating the code into a logical formula, calls to solvers are
%% expensive.

%% \paragraph{Discussion on completeness}
%% We cannot guarantee that we'll find a refactoring whenever one exists.
%% The fuzzer in the synthesis phase may fail to find a candidate.

%% \section{Some research questions}

%% What if the new method doesn't maintain observational equivalence?
%% TODO: Check existing projects to see how many do preserve equivalence.
%% For the rest, is there a notion of partial equivalence that ensures the equivalence
%% for the new projects minus the differences introduced by the new function.

%% How easy is for the fuzzer to handle such structured inputs as we need in the
%% synthesis phase?


%% \subsection{For the experimental evaluation}
%% \begin{itemize}
%% \item Pick libraries that have deprecated instances.
%% \item Pick users of these libraries (i.e. open source projects that are actively maintained).
%% \item Make pull requests and see how many get merged.
%% \end{itemize}  

%% \section{Context-sensitive vs. context-insensitive refactoring}

%% \paragraph{Context-insensitive refactoring}
%% We consider different refactoring options. The first and most simple
%% one is the so called ``context-insensitive'' refactoring, where we
%% find a refactoring for the deprecated code that works irrespective of
%% context. This means that, once such a refactoring is found, it can be
%% used to replace all the uses of the deprecated code, e.g. a deprecated
%% method invocation will be replaced with the same refactored code
%% irrespective of the actual parameters or rest of the state at the call
%% site.

%% For instance, if we want to refactor the call to method
%% \texttt{toRefactor} in the code below, then we search for a refactoring that is
%% observationally equivalent to the given method irrespective of the
%% context of the call.

%% \begin{lstlisting}[mathescape=true]
%% class NoContext {
%%   int x;

%%   public double toRefactor(int y, int z) {
%%     return (double) x + y + z;
%%   }
%% }
%% \end{lstlisting}
 
%% This means that the state that we can vary in order to check for
%% observational equivalence includes \texttt{x, y} and \texttt{z}.

%% \paragraph{Context-sensitive refactoring}
%% The refactoring context consists of the context where the code to be refactored
%% is placed. For instance, in the snippet below, if we are trying to refactor the call to the deprecated
%% function \texttt{f}, then the context gives us the valuation $[\texttt{x}\mapsto 1]$ for the function's argument. 

%% \begin{lstlisting}[mathescape=true]
%%   int x = 1;
%%   A a = new A();
  
%%   a.f(1)
%% \end{lstlisting}
    
%% We now look at the possibility of considering the refactoring context
%% when searching for a refactoring. This gives us the option of starting
%% with very little context and gradually increasing it until finding a
%% refactoring. \todo{Adjust this based on what the experiments do.}

%% The other option is to find a refactoring that takes into consideration
%% the calling context. For instance, in the code below we have two
%% calls to \texttt{toRefactor}, one in method \texttt{foo} and one in
%% method \texttt{bar}. When considering the calling context, we have to
%% find two different refactorings, one for each of the method calls.
%% For the call in \texttt{foo}, the state that we need to consider for observational
%% equivalence contains \texttt{ctx} and \texttt{a}, whereas for the call in method
%% \texttt{bar} it contains \texttt{ctx, a, b, c, d} and \texttt{e}.

%% \begin{lstlisting}[mathescape=true]
%%   class Context1 {
%%     NoContext ctx = new NoContext();

%%     public double foo(int a) {
%%       return ctx.toRefactor(a, a);
%%     }
%%   }

 

%%   class Context2 {
%%     NoContext ctx = new NoContext();

%%     int d;
%%     int e;

%%     public double bar(int a, int b, int c) {
%%       return ctx.toRefactor(a, b + c + d + e);
%%     }
%%   }
%% \end{lstlisting}


%% Fuzzing:

%% someNoContext.x = x_*;

%% someNoContext.toRefactor(y_*, z_*);

%% Possible follow-up:
%% - if we have a sizeable codebase, the user might have to do 1,2 deprecated
%% refactorings and then the synthesisers can use the PRs done by the user
%% to seed the synthesiser and do the other thousands of refactorings
%% automatically.

  \section{Implementation}

  While in the previous sections, we presented our technique from a formal point of view,  in this section we discuss details related to some of our implementation choices.  

\subsection{Using fuzz testing for synthesis} \label{sec:fuzzing}

In order to generate programs, we make use of JQF~\cite{DBLP:conf/issta/PadhyeLS19}, a  %coverage-guided property-based
fuzz testing platform for Java.
%
As explained in Section~\ref{sec:encoding}, we use JQF for two tasks. Firstly, in the synthesis phase, 
JQF is generating the refactored block of code.
Secondly, in the verification phase, JQF generates
inputs that can differentiate between the original and refactored codes.
The former task in particular is a difficult setting for fuzzing because programs are
highly structured, whereas fuzzers often work with unstructured inputs
that can be generated via byte-level mutations such as bit flips.

JQF is designed to handle structured inputs, where inputs of type \texttt{T}
are generated by a backing \texttt{Generator<T>}. JQF provides a library of
generators for basic types such as primitive values. We implement custom
JQF generators for the synthesis and verification phase of the CEGIS loop. In
the case of the former the generator produces candidate refactorings, in the latter
it produces counterexample inputs %heaps
for candidate verification.

\subsection{Equivalence reduction}
JQF never generates the same exact program twice. However it may generate many
syntactically different, but semantically equivalent ones.
Program synthesis techniques make use of equivalence reduction in order to
reduce the number of equivalent programs that get explored.
For example, \citet{DBLP:conf/cav/AlbarghouthiGK13} 
prune the search space using observational equivalence with respect to a set of input/output examples, i.e., two programs are considered to be in the same equivalence class if, for all given inputs in the set of input/output examples, they produce the same outputs. Alternatively, \citet{DBLP:conf/vmcai/SmithA19} generate only programs in a specific normal form, where term rewriting is used to transform a program into its normal form. In~\cite{DBLP:journals/corr/KoukoutosKK16}, Koukoutos et al. make use of attribute grammars to only produce certain types of expressions in their normal form, thus skipping other expressions
that are syntactically different, yet semantically equivalent.
While we plan on investigating some of these directions as part of future work,
our current technique is still effective without equivalence reduction.
Our conjecture is that, especially for the CodeHints-library, this is due to the reduced number of components. 
\todo{Do we want to mention number of components? Do we use any heuristic at all for this?}
%% given the restricted set of instructions in the core library,
%% our current technique is still effective (as shown by the experimental evaluation).

%% We plan on addressing this 
%% This may be addressed
%% in future work by explicitly restricting redundancy in our instruciton set.
%% Since the instruction sets in our experiments are already restricted by type
%% information and other hints, this effect did not appear to affect the
%% effectiveness of our algorithm.
%% Next, we discuss a few techniques that we use to reduce the number of
%% generated programs that are semantically equivalent.


\subsection{Checking aliasing}

In Section~\ref{sec:equiv}, we discussed about checking program equivalence with respect to a concrete input. As part of this, 
we must check that the refactored code preserves the aliases present in the original code (see Definition~\ref{def:prog-equiv-add}).

%% In our implementation we enforce a strict notion of aliasing. In
%% particular, every reference variable encountered in the original and
%% refactored code is assigned a strictly increasing symbolic id
%% $sid(v)$. We start from the same initial symbolic id in the original
%% and refactored code.  Then, every live variable at the end of the
%% original code (which according to Definition~\ref{} is also live at
%% the end of the refactored code) must be assigned the same symbolic id
%% by the original code and the refactored one.

%% Notably, this is stronger than needed as it means that variables are declared in the same order by the
%% original and the refactored program
%% Then, two variables $v_1$ and $v_2$ in $P$ (where $P$ is either the original or the refactored code)
%% are aliases if 

%\todo{Discuss this.}
Intuitively, when checking preservation of aliases, we want to preserve the equivalence classes induced by the aliasing relation.
For simplicity, in our implementation, we enforce a stricter check than necessary.
In particular, all the objects
%(memory locations)
that are being referenced during the code's execution
are assigned increasing symbolic identifiers.
Then, we enforce aliasing preservation (condition (4) in Definition~\ref{def:prog-equiv-add}),
by checking that, for all variables defined by both the original and the refactored code,
the objects they reference have the same symbolic id.

For illustration, in the original code in Example~\ref{ex:aliasing}, the object of type \texttt{Dimension} referenced by variable \var{dim1}
is assigned symbolic value \var{s_1}, whereas the object referenced by \var{dim2} is assigned symbolic value \var{s_2}.
In a similar manner, the object referenced by both \var{dim1} and \var{dim2} in the refactored code is assigned value \var{s_1}.
Then, the aliasing check fails as, in the original code, the object referenced by \var{dim2} has symbolic value \var{s_2},
whereas, in the refactored code, the object referenced by \var{dim2} has symbolic value \var{s_1}.

While this is a much stronger requirement than needed, it was sufficient for our experiments.
For future work, we plan on relaxing it and explicitly tracking the equivalence classes induced by the aliasing
relation.

%\todo{Refer to the new example obtained from Pascal.}

%% heap equivalence, we enforce a strict notion of aliasing
%% equivalence.
%% While exploring the heaps and comparing
%% them for value equivalence, every pointer encountered is assigned
%% a strictly increasing symbolic id $sid(v)$.
%% Two heaps $H_A$, $H_B$ are only considered equivalent if
%% $\mathop \forall \limits_{i=1}^{n} sid(v^A_i)=sid(v^B_i)$. This is a strong
%% under-approximation and may be subject to improvement in future work, but was
%% sufficient for the scope of our experiments.

%% Then, we can check whether the set of aliases is preserved in the
%% refactored program. For instance, if \texttt{obj1} and \texttt{obj2}
%% are aliases in the original program, then they must be aliases also
%% in the second program.
%\todo{check exactly what this is used for.}

\subsection{Sources of unsoundness and incompleteness}\label{sec:incompleteness}
As explained in Section~\ref{sec:encoding}, due to the use of fuzz testing in the synthesis
phase, our technique may fail to find a refactoring even when one
exists (i.e. it is {\em incomplete}), whereas using fuzz testing in the verification phase may result in finding a refactoring that is not equivalent to the original on all
inputs (i.e. our technique is {\em unsond}).

%With respect to the use of fuzzing,
%In order to guarantee the soundness and completeness of the
%proposed refactoring technique,
While we could attempt to swap fuzz testing with a formal verification technique,
program verification is undecidable in general.
Even for restricted, decidable fragments, such
techniques tend to be expensive as they generally require some form of
symbolic execution and calls to off-the-shelf solvers.  Moreover,
programming languages evolve faster than formal verification techniques and
therefore new language features might not be supported by the front ends of
such techniques. An attempt at using formal methods for proving
observational equivalence during the refactoring process was made in~\cite{DBLP:journals/corr/abs-1712-07388} and exposed the aforementioned limitations.

Besides the use of fuzz testing, we identified three other potential sources of unsoundness,
which we discuss next.

Firstly, unsoundness can be caused by I/O,
which is not part of the JVM state. We currently don't check
that the original and refactored code perform the same I/O.
%the possibility that the static initialiser performs some I/O,. 

Secondly, our algorithm does currently not explore the entire classpath for
potential overrides of the method to refactor. This may lead to unsound results
when different subclasses of the original class are used polymorphically in the
refactored context.

Finally, as described in Sec.~\ref{sec:equiv}, we rely in some cases on
\texttt{equals} implementations for equivalence comparison.  While we
strictly filter which \texttt{equals} implementations we consider, if any of
them do not accurately identify an equivalent program state, our refactoring
may be unsound.

%%However, we make no guarantee about correctness with respect to such operations
%% anyway, whether static or instance state.}


%\todo{Other sources of incompleteness and unsoundness?}

%% such a technique would require symbolic execution, which is no-
%% toriously difficult for real-world programs due to features such as
%% loops, library functions, complex data structures. The most success-
%% ful such verification techniques are either bounded (i.e. check that
%% an erroneous state cannot be reached within a bounded number of
%% loop unrollings) or require user input in the form of loop invariants.
%% While the former class of techniques provides limited soundness
%% guarantees, the latter requires intricate help from the user. In fact,
%% we are not aware of any sound and automatic symbolic verification
%% method that can handle the kind of code we are interested in.

%% Discuss tradeoff: symbolic execution is expensive; programming
%% languages evolve faster than verification techniques and therefore
%% many new features are not supported by their front ends (and/or
%% backends depending on how complex the new feature is); even
%% after translating the code into a logical formula, calls to solvers are
%% expensive.


\subsection{Instrumentation and isolation}

We use reflection to invoke the original method to refactor with fuzzed inputs,
as well as our synthesised refactoring candidates. This allows us to dynamically
invoke new candidates without the need for compilation. The state of a Java
program is modelled by the current program stack as well as its heap consisting
of instance variables and static field values. Static field values are stored
with their respective classes, which in turn are loaded by class loaders. Java
allows to load the same class in different class loaders, which creates
independent copies of its static fields.

In the verification phase, in order to fully isolate the program state during the execution of the original and refactored code from each other, we load all involved classes in separate
class loaders. These class loaders are disposed immediately after the curent set
of fuzzed inputs are executed, and new class loaders are created for the next
inputs (which will be used in the next iteration of the CEGIS loop).
Classes that do not maintain a static state are loaded in a shared
parent class loader to improve performance.

The OpenJDK Java virtual machine implementation does not allow us to load
classes contained in the \texttt{java.lang} package in such an isolated class
loader. For such classes we cannot apply refactorings that depend on static
fields, as they cannot be reset and will retain the state of previous
executions. Instead of observing the effect of one isolated refactoring
candidate, we would observe their accumulated effect, leading to both
incompleteness and unsoundness depending on the context. For the scope of our
experiments this did not pose a problem, since most of the affected classes in
the \texttt{java.lang} package do not maintain a static state, and the ones who do
were irrelevant to our refactorings.

%Everything that is part of our comparison is in the isolated class loader.


%% For instance user defined types will usually be located in the isolated
%% class loader, enabling the comparison.
%% However, what do we do about wrapper object aliasing?
%% For anything outside the class loader, we use reference equality.
%% PAK: I think this should be in a separate section. Being loaded in the isolated
%% class loader or not doesn't prohibit comparison per se.

%% We also never use reference equality,
%% but rather rely on native `equals' implementations if they satisfy certain criteria.
%% This should probably also be explained in its own subsection.

%% One potential issue when checking equivalence of two blocks of code
%% is the treatment of loaded classes. In particular, one program might
%% load more classes than the other, but still have the exact same effect
%% as the other one. This can happen for instance if one program calls a
%% helper method from a class that needs to be loaded, whereas the other
%% program inlines the same method, thus avoiding loading the class.  Our
%% assumption is that loading and initialization don't perform any
%% changes outside of the observable state already checked by the
%% existing equivalence check.  While this assumption is generally safe
%% to make, there might be some cases when this is not the case, e.g. the
%% class initializer might print something on the screen. For now, we
%% don't handle these cases.
%% \todo{So we don't need to load the exact same classes? What if static fields are changed? -
%% PAK: We check that all static fields in classes that were loaded by either program are equivalent.
%% That means that if one program didn't load a class, we load it for it, and check that the
%% initial state of that class is the same as the other program's. 



%% The goal of our instrumentation is to execute a program candidate in
%% the same context as the original, deprecated method. The original
%% method can affect the program state by virtue of its return value,
%% field assignments in the case of instance methods, and static field
%% assignments. In order to account for these effects, our
%% instrumentation passes a reference to the original method's object
%% instance, if present, as an argument to the program candidate.
%% An example of this is presented in
%% Fig.~\ref{ex:side-effects-instrumentation}.

%% \begin{figure}
%% \begin{lstlisting}[mathescape=true,showstringspaces=false]
%% // Redundant snippet:
%% Date today;
%% Date tomorrow;
  
%% void init(int year, int month, int day) {
%%   // Original:
%%   this.setDates(year, month, day);

%%   // Instrumented:
%%   Program.of(0xabcd).execute(year, month, day, this);
%% }
  
%% @Deprecated
%% private void setDates(int year, int month, int day) {
%%   final Calendar calendar = Calendar.getInstance();
%%   calendar.set(year, month, day);
%%   this.today = calendar.getTime();
%%   calendar.add(Calendar.DAY_OF_MONTH, 1);
%%   this.tomorrow = calendar.getTime();
%% }
%% \end{lstlisting}
%% \caption{Deprecated side-effects instrumentation.}
%% \label{ex:side-effects-instrumentation}
%% \end{figure}

%% Fig.~\ref{ex:date-instrumentation} illustrates an example where no
%% such relevant instance object exists and thus only the original
%% arguments are passed as arguments into the program candidate.

%% \begin{figure}
%% \begin{lstlisting}[mathescape=true,showstringspaces=false]
%% // Redundant snippet:
%% static void main(String[] args) {
%%   // Original:
%%   Date date = new Date(120, 12, 30);

%%   // Instrumented:
%%   Date date = Program.of(0xabcd).execute(120, 12, 30);
%% }
%% \end{lstlisting}
%% \caption{Deprecated `Date' instrumentation.}
%% \label{ex:date-instrumentation}
%% \end{figure}

\subsection{Abstract classes and interfaces}

The counterexamples generated by the verification phase may refer to
abstract classes and interfaces. These are by default instantiated
using the mocking framework Mockito.

Alternatively, we also curate a
list of explicit constructors
of subclasses to be used in favour of Mockito mocks for certain types, and users
have the option to extend this list with a custom configuration. This is
particularly useful when the default behaviour of mocked objects under-approximate
the behaviour of the explicit constructors of subclasses.
\todo{think if it's over or under-approximation.}
In such situations, the use of mocked objects can lead to
spurious refactorings.

This problem generally appears whenever methods are overriden in subclasses.
A trivial example of this limitation is refactoring the
method \texttt{layout} in the abstract class \texttt{java.awt.Component}. The
method is not abstract, but has an empty body and is meant to be overriden by
subclasses. Using this empty body as a specification will only guarantee a sound
refactoring for subclasses that do not override it. Our approach is still
guaranteed to find the preferred refactoring of using \texttt{doLayout} instead,
since we take the Javadoc hint into account. However, a more complete approach
in general would be to fuzz against all available subclasses of
\texttt{Component} on the classpath.

We explicitly avoid constructors that are not amenable to fuzzing, such as
collection constructors that take an integer capacity argument, where an
unlucky fuzzed input might lead to an out of memory error.

\subsection{Parsing the @code hints}

As explained in Section~\ref{sec:components-seeding}, when seeding the component library, our algorithm must
interpret Javadoc hints. % provided by the developer.
In particular, \texttt{@code} blocks inside \texttt{@deprecated} sections are interpreted as code
hints, and we attempt to parse them as Java expressions. Since code hints are
not always expressed as well-formed Java, we customised the
GitHub Java parser
%%framework
to accept undeclared identifiers and type names
as arguments. For instance, the Javadoc hint in Figure~\ref{ex:javadoc-hint} suggests using
\texttt{contains(int, int)}, which would normally cause a parsing error as the \texttt{int} type
appears in the place of argument names. In our setting, we accept this hint as valid.

%% provides an example of
%% a valid Javadoc hint.

\begin{figure}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
/**
* Checks whether or not this {@code Rectangle} contains the
* point at the specified location {@code (X,Y)}.
*
* @param  X the specified X coordinate
* @param  Y the specified Y coordinate
* @return    {@code true} if the point
*            {@code (X,Y)} is inside this
*            {@code Rectangle};
*            {@code false} otherwise.
* @deprecated As of JDK version 1.1,
* replaced by {@code contains(int, int)}.
*/
@Deprecated
public boolean inside(int X, int Y) {
  // ...
}
\end{lstlisting}
\caption{Javadoc hint example.}
\label{ex:javadoc-hint}
\end{figure}

Additionally, the code example is parsed as if it were invoked in the context of
the method to refactor, such that imports or the implicit \texttt{this} argument
are considered during parsing.

\section{Experimental results}\label{sec:experimental-results}
Our benchmark suite consists of the first 127 deprecated methods from the Oracle
JDK 15 Deprecated API documentation~\cite{OracleJdk15DeprecatedAPI} for which
there exist refactorings that are semantically equivalent to the original code.
Besides deprecated methods that don't have a semantically equivalent refactoring
(see Section~\ref{sec:semantically-different-refactorings}),
we also excluded methods with I/O side-effects, which are currently
unsupported by our implementation (see Sec.~\ref{sec:incompleteness}). Other
reasons for exclusion were: deprecation without replacement, methods
inaccessible by non-JCL classes, and native methods.

\subsection{Experiment design}
We use JQF in two modes: (1) with Zest~\cite{DBLP:conf/issta/PadhyeLSPT19}
guidance, which incorporates
feedback from the test program in the form of semantic validity of
test inputs and the code coverage achieved during test execution, and
(2) with random guidance, which randomly generates test inputs without using
code coverage feedback.
%
%% However,
%% random-from-scratch input generation is exceedingly unlikely to
%% generate inputs fitting precise bug-revealing conditions, like those
%% described above
%
%
The coverage feedback used by Zest means that JQF uses lightweight program
instrumentation to trace the code coverage reached by each generated
input that is fed to the program under test.  %% Basically, the program
%% is continuously executed with randomly generated inputs. However,
Instead of generating inputs from scratch, coverage-guided fuzzers
evolve a set of saved inputs. If a new input leads to an increase
in code coverage, it is saved for subsequent evolution.


In our experiments, we compare four configurations of our algorithm against each other. The
configurations differ in terms of the search space of programs they consider
as well as the JQF fuzzing guidance applied. Configurations marked as {\bf TI}
only consider type information when building the component library, whereas
configurations marked as ({\bf TI/CH}) consider both type information and Javadoc
code hints. Equally, configurations marked as {\bf Rand} use JQF's random fuzzing
guidance, whereas {\bf Zest} uses JQF's coverage-guided Zest guidance.

In Sec.~\ref{sec:experimental-results}, for each configuration we evaluate how
many sound as well as unsound refactorings are produced, how many refactoring
opportunities were missed and the average time to successfully produce a
refactoring. We bound the search by at most 500 inputs and 5 minutes per verification
phase, and at most 2 minutes per synthesis phase. Experiments were performed on
a Windows 10 computer with Oracle JDK 15.02, 32 GB of RAM and an Intel Core
i7-4790 CPU dual core at 3.60 GHz.

\subsection{Results}\label{sec:experimental-results}

Tab.~\ref{tab:configuration-results} provides an overview about the number of
sound refactorings (\checkmark), missed refactorings (\xmark) and unsound
refactorings (\lightning) produced per configuration, as well as the average
runtime per refactoring. Our experiment did not yield significant performance
differences between using JQF's coverage-guided Zest guidance and its random
guidance. Using Javadoc Code Hints increased the rate of successful refactorings
by 51\% for Zest guidance and 33\% for random guidance.

\begin{table}[h]
\begin{tabular} {|l|r|r|r|r|}
\hline
Config  & \checkmark & \xmark & \lightning & $\diameter$ runtime (s) \\ \hline
Zest TI      & 55 & 58 & 14 & 228.4 \\ 
Zest TI/CH   & 83 & 39 &  5 & 197.1 \\ 
Rand TI      & 61 & 55 & 11 & 217.7 \\ 
Rand TI/CH   & 81 & 40 &  6 & 207.2 \\  \hline\hline
\end{tabular} 
\caption{Experimental results per configuration.}
\label{tab:configuration-results}   
\end{table}

For the Zest TI/CH configuration, out of the 39 missed refactorings 13 were due
to a failure to identify a suitable code hint.
Tab.~\ref{tab:configuration-results-ch} shows the same evaluation as
Tab.~\ref{tab:configuration-results}, but excluding refactorings where we failed
to identify a suitable code hint, further highlighting the importance of Javadoc
code hints. Excluding failures due to missing code hints, our success rate
increases from 65\% to 74\% for the Zest TI/CH configuration.

\begin{table}[h]
\begin{tabular} {|l|r|r|r|r|}
\hline
Config  & \checkmark & \xmark & \lightning & $\diameter$ runtime (s) \\ \hline
Zest TI/CH   & 83 & 23 &  5 & 197.1 \\ 
Rand TI/CH   & 81 & 24 &  6 & 207.2 \\  \hline\hline
\hline
\end{tabular} 
\caption{Results with present code hints.}
\label{tab:configuration-results-ch}   
\end{table}

13 further refactorings were missed because our instruction is too conservative.
The current instruction set checks whether it can construct well-formed 
candidates using methods in the class containing the method to refactor, as well
as any class used in the signature and Javadoc of the method to refactor. For
these 13 methods the correct refactoring requires constructing an object of a
type which does not occur in any of these sources, or invoking a method which is
not contained in any of the aforementioned types.

Three further refactorings were missed due to the size cap configured for
refactored programs during the experiment, and another three refactorings were
missed because our engine does not yet consider polymorphic or generic type
relations. Finally, two more refactorings were missed because the method return
value was dependent on an external system state which changed frequently between
invocations
(e.g. \code{getFreePhysicalMemorySize} in \code{OperatingSystemMXBean}),
and thus appeared nondeterministic to our engine.

All other refactoring opportunities were missed due to fuzzing
timeouts. The five unsound refactorings occured because the method to refactor
was a default method with an empty body, meant to be overridden by subclasses.
To find a sound refactoring in these cases our algorithm should expand its
equivalence constraint to types who override the method to refactor.
Tab.~\ref{tab:configuration-results} also highlights that Javadoc Code Hints
significantly reduce the likelihood of unsound refactorings in this context.

\section{Semantically different refactorings}\label{sec:semantically-different-refactorings}


%% \begin{figure}
%% \begin{lstlisting}[mathescape=true,showstringspaces=false]
%% void main(String[] args) {
%%   // Deprecated:
%%   Date date = new Date(120, 12, 30);
 
%%   // Should have been:
%%   final Calendar calendar = Calendar.getInstance();
%%   calendar.set(2020, 12, 30);
%%   final Date date = calendar.getTime();

%%   // Or:
%%   final Date date = new GregorianCalendar(2020, 12, 30)
%%                       .getTime();
%% }
%% \end{lstlisting}
%% \caption{Deprecated method example.}
%% \label{ex:deprecated-method}
%% \end{figure}


Sometimes, the deprecated and the refactored features are not semantically
equivalent on the entire domain. Reasons for this might be that a bug
was fixed, a certain functionality was improved, or simply the fact
that the deprecated feature is only expected to be used on restricted
parts of the input domain. In such a case, the deprecated and the new
feature may not be semantically equivalent on the entire input domain.

For illustration, let's consider the example in Figure~\ref{ex:three-dates}.
In the example, we make use of the constructor \texttt{new Date(year, month, day)}, 
which is deprecated with the 
recommendation to use the \texttt{Calendar} class instead.
The refactoring is not trivial given that the 
\texttt{Date} constructor expects its year parameter to be an offset
from 1900.  This needs to be
transformed by adding 1900 when using \texttt{Calendar} API, as shown in the
example. Moreover, as already seen in the motivational example in  Figure~\ref{ex:deprecated-method-other},
the \texttt{Calendar} constructor is protected,
meaning that we must use \texttt{getInstance} to obtain a
\texttt{Calendar} object.
Alternatively, the \texttt{GregorianCalendar} class may be used with
similar difficulties.
In the example, we use \texttt{date1}, \texttt{date2} and \texttt{date3} to denote the three distinct ways of constructing a date.

%% For illustration, let's consider the three distinct ways of
%% constructing a date captured in Figure~\ref{ex:three-dates} and
%% denoted by \var{date1}, \var{date2} and \var{date3}.

\begin{figure}
  \begin{lstlisting}[mathescape=true,showstringspaces=false]
  // Deprecated:
  Date date1 = new Date(year, month, day);

  // Should have been:
  Calendar calendar = Calendar.getInstance();
  calendar.set(1900 + year, month, day, 0, 0, 0);
  calendar.set(Calendar.MILLISECOND, 0);
  Date date2 = calendar.getTime();
    
  // Or:
  Date date3=new GregorianCalendar(1900+year,month,day).
             getTime();
  \end{lstlisting}
\caption{Deprecated `Date' example.}
\label{ex:three-dates}
\end{figure}

%% In the example, \var{date1} uses the deprecated
%% \var{Date(year, month, day)} constructor, whereas \var{date2} and
%% \var{date3} make use of the recommended \var{Calendar} and
%% \var{GregorianCalendar} classes.
Notably, the ways in which \texttt{date2} and \texttt{date3} are computed
represent valid refactorings for the original code computing
\texttt{date1}. However, when we provide this example to our
verification phase (as described in Section~\ref{sec:encoding}), we obtain the following
counterexample:

  \begin{lstlisting}[mathescape=true,showstringspaces=false]
    int year = -89412298;
    int month = 1439435067;
    int day = 378993182;
  \end{lstlisting}

  For these values of \texttt{year}, \texttt{month} and \texttt{day}, the three
  dates evaluate to:

  \begin{lstlisting}[mathescape=true,showstringspaces=false]
    date1: "Sat May 02 00:00:00 CEST 31580172"
    date2: "Fri Jul 02 00:00:00 CEST 31580799"
    date3: "Fri Jul 02 00:00:00 CEST 31580799"
  \end{lstlisting}

  Where \texttt{date1} evaluates to a different date than \texttt{date2} and \texttt{date3}. In principle, this should not affect any use case as the counterexample
  \texttt{year}, \texttt{month} and \texttt{day} are clearly artificial and outside the expected domain of a calendaristic date.
  In particular, for this example, we deduced that the negative year is the cause for the different values of \texttt{date1}, \texttt{date2} and \texttt{date3}.

  This counterexample is enough to stop our synthesiser from finding any of the correct refactorings in Figure~\ref{ex:three-dates}.
  To overcome this problem, we plan on computing preconditions for the verification phase. Namely, for this example, we would collect all the concrete values that
  \texttt{year}, \texttt{month} and \texttt{day} get instantiated to in the unit tests associated with the given project, and use them to
  infer a precondition over the domain of these three variables. For \texttt{year}, this should tell us that the expected year must be positive.
  Consequently, the verifier won't attempt to find counterexamples involving negative years, thus eliminating the counterexample above.


  
\section{Related Work}

\paragraph{Program synthesis}


CEGIS based approaches to program synthesis have been previously used
for program transformations such as superoptimisation and
deobfuscation~\cite{DBLP:conf/icse/JhaGST10}.  In
\cite{DBLP:journals/corr/abs-1712-07388}, David et al.~present an
automatic refactoring tool that transforms Java with external
iteration over collections into code that uses Streams. Their approach
is based on CEGIS and makes use of formal verification to check the
correctness of a refactoring.  Cheung et al.~describe a system that
automatically transforms fragments of application logic into SQL
queries~\cite{DBLP:conf/pldi/CheungSM13} by using a CEGIS-based
synthesiser to generate invariants and postconditions that validate
their transformations (a~similar approach is presented
in~\cite{DBLP:conf/cc/IuCZ10}).  While our approach is also based
on CEGIS, we are guided by code hints and types in
order to efficiently prune the search space. Without this guidance,
the current refactoring would not be feasible.  

% type-directed synthesis
Type information has been extensively used in program synthesis to
guide the search for a solution~\cite{DBLP:conf/sfp/Katayama05,DBLP:conf/pldi/FeserCD15,DBLP:conf/pldi/OseraZ15,DBLP:journals/pacmpl/LubinCOC20}.
In our work, we combine type information with code hints.
%
% component-based synthesis
Another direction that inspired us is that of component-based synthesis~\cite{DBLP:conf/icse/JhaGST10,DBLP:conf/pldi/GulwaniJTV11,DBLP:conf/popl/FengM0DR17}, where the target program is generated by composing components from a library. Similarly
to these approaches, we use a library of components for our program
generation approach. However, our technique uses information about types
and code hints to build the component library, which is specific to each refactoring.

%% For the intro:
% not correct-by-contruction, preserves the behaviour, refer to the paper
% on refactoring concurrent programs.
%% for equivalence checking:
%% we use an explicit return variable ret, which is live. Also, we make "this explicit".
%% Essentially, we must capture the whole program state, consisting of return values and heap. 
%% Todo: related work, alising check, intro, equiv check.


%% An approach to program synthesis very similar to ours is Syntax Guided
%% Synthesis (SyGuS)~\cite{sygus}.  SyGuS synthesisers supplement the logical
%% specification with a syntactic template that constrains the space of allowed
%% implementations.  Thus, each semantic specification is accompanied by a
%% syntactic specification in the form of a grammar.  Other second-order
%% solvers are introduced in~\cite{DBLP:conf/pldi/GrebenshchikovLPR12,
%% DBLP:conf/cav/BeyenePR13}.  As opposed to ours, these focus on
%% Horn clauses.


  %% The main difference (besides the actual
%% goal of the work, which is different from ours) to our work is that the
%% lists they operate on are immutable and do not support operations such as
%% remove.  Capturing the potential side effects caused by such operations is
%% one of our work's main challenges.

Program synthesis is generally guided by the principle of correct-by-construction, meaning that it provides strong correctness guarantees about the generated code.
As opposed to that, our work is guided by program testing. This is similar in nature with genetic programming~\cite{Koza92} and genetic improvement~\cite{DBLP:journals/dagstuhl-reports/PetkeGFL18,7911210}. In particular, the latter has been used for program refactoring. Genetic programming and genetic improvement obtain candidate programs by applying operations analogous to genetic processes to an existing population of programs. Conversely, we pose the code generation problem as safety verification.



%% Often, genetic improvement
%% \cite{DBLP:journals/dagstuhl-reports/PetkeGFL18} is used for the
%% purpose of code refactoring. Due to the manner in which such works measure
%% the fitness of potential refactorings, genetic improvement cannot vary
%% the refactoring context.  Conversely, our technique allows varying this
%% context until a refactoring is being found.


\paragraph{Program refactoring}

With respect to works targeting the refactoring of deprecated instances, the work of Perkins directly replaces calls to deprecated methods by their bodies~\cite{DBLP:conf/paste/Perkins05}.
As mentioned earlier in the paper, we believe that this solution does not follow the intention of the language designers. Moreover, it can
introduce concurrency bugs. Notably, the authors of \cite{10.1007/978-3-642-14107-2_11}
show that it is very easy for a refactoring that works on concurrent
programs to introduce concurrency bugs by enabling new interactions between
parallel threads. %They also provide techniques to make such refactorings behavior-preserving.

A related class of techniques aim to adapt APIs after library updates. Such techniques
automatically identify change rules linking different library releases~\cite{DBLP:conf/icse/WuGAK10,DBLP:conf/kbse/Huang0PW021}. Conversely to our work, a change rule describes a match between methods existing in the old release, but which have been removed or deprecated in the new
one, and replacement methods in the new release. However, they do not provide the actual refactored code.

%% In~\cite{DBLP:conf/kbse/Huang0PW021}, Huang et al. automatically find replacements for missing APIs in library update (an API is considered as a public method in a public class). As new library versions are released, some APIs may get deprecated, removed or refactored.
%% The focus in this work is on locating a replacement API through heuristics based on method signatures, rather than on finding an equivalent block of code.
%% The tool presented in this paper, {\sc RepFinder} searches deprecation messages, the current library and external libraries in order to find replacement APIs. Replacement APIs must have either identical signatures to the missing API, or similar. For the latter category, {\sc RepFinder} computes the weighted sum of the distances of return types, method names and parameter types. Finally, the API with the smallest distance is selected. As opposed to our technique, this work offers no guarantees as it doesn't
%% investigate the body of the deprecated method or of the replacement one. Moreover, API calls
%% are simply replaced by some other API call, rather than more complex code as in our situation.


%name change, signature change, move to a different package

%% The signature of mo can be changed in
%% ln, including its return type, method name and parameter type.
%% mo can also be move into a different class in ln.

%% At the class level, mo can be substituted
%% by a method from another class, either with the same method
%% name or a different method name. At the method level, mo
%% can be substituted by a different method from its own class.



There are several rule-based source-to-source transformation systems that provide languages in which
transformation rules based on the program's syntax can be expressed~\cite{stratego,txl}. 
%% Syntax-driven refactoring base program transformation decisions
%% on observations on the program's syntax tree.  Visser
%% presents a purely syntax-driven framework~\cite{stratego}.  The
%% presented method is intended to be configurable for specific
%% refactoring tasks, but cannot provide guarantees about semantics
%% preservation.
%% In~\cite{txl}, Cordy et al. introduce TXL, a programming language and rapid prototyping
%% system specifically designed to support structural source transformation.
As opposed to our work, such systems require the user to provide the actual transformation rules and are syntax-guided.


Search-based approaches to automating the task of software refactoring, based
on the concept of treating object-oriented design as a combinatorial optimisation
problem, have been also proposed~\cite{search1,search2}. They usually make use of techniques such as
simulated annealing, genetic algorithms and multiple ascent hill-climbing.
%O'Keffe and Cinn{\'{e}}ide present a search-based refactoring
%refactoring~\cite{search1, search2}, which is similar to syntax-driven
%refactoring.  They rephrase refactoring
%which is rephrased as an optimisation problem,
%using code metrics as fitness measures~\cite{search1, search2}.  %% As such, the method optimises
%% syntactical constraints and does not take program semantics into
%% account.
While our technique is search based, the search is guided by types, code hints, as well as counterexamples
provided by property-based testing.

Closer to our work, several refactoring techniques make explicit use of some form of semantic information.
%With respect to automated program refactoring,
Khatchadourian et al. use a type inference algorithm to automatically transform legacy Java code (pre Java 1.5) to use the \texttt{enum} construct~\cite{sawin}.
%\cite{sawin} by Sawin et al.,
Other automated refactoring techniques aim to transform programs into a particular design pattern~\cite{chris,bae}.
%In \cite{bae}, Bae et al. propose an automated approach to
%identifying the candidate spots, then on which the defined refactoring strategy would be applied for the
%~and \cite{chris} by Christopoulou et al.  In contrast to these approaches,
%our procedure constructs an equivalence proof before transforming the
%program.
%
%% In \cite{conf/sigsoft/GyoriFDL13}, Gyori et al. present a
%% similar refactoring to ours but performed in a syntax-driven manner.
%
%
%
Steimann et al.~present Constraint-Based Refactoring in \cite{Steimann2011},
\cite{Steimann2012Pilgrim} and \cite{Steimann2011KollePilgrim},
where given well-formedness logical rules about the program are translated into constraints that are then solved to assist the refactoring.
%% , their approach
%% generates explicit constraints
%% over the program's abstract syntax tree to
%% prevent compilation errors or behaviour changes by automated refactorings.
% This gives rise to a flexible framework of customisable refactorings,
% implementable through a refactoring constraint specification language
% (cf. \cite{Steimann2011KollePilgrim}).
%% The approach is limited by the information
%% a program's AST provides and thus favours conservative implementations of
%% syntax-focused refactorings such as \emph{Pull Up Field}.
%
Fuhrer et al.~implement a type constraint system to introduce missing type
parameters in uses of generic classes (cf. \cite{DBLP:conf/ecoop/FuhrerTKDK05})
and to introduce generic type parameters into classes that do not provide
a generic interfaces despite being used in multiple type contexts
(cf. \cite{DBLP:conf/icse/KiezunETF07}).
%
% Raychev et al.~present a semi-automatic approach where users perform
% incomplete refactorings manually and then employ a constraint solver
% to find a sequence of default refactorings such as move or rename
% which include the users' changes. The engine is limited to syntactic
% matching with the users' partial changes and does not consider program
% semantics~\cite{DBLP:conf/oopsla/RaychevSSV13}.
%
% Weissgerber and Diehl rely on meta information to classify changes
% between software versions as refactorings~\cite{weiss}.  The technique
% aims to identify past refactorings performed by programmers, but is
% not a decision procedure for automated refactorings.
%
%
% Bavota et al. implement refactoring decisions in \cite{Bavota:2011:IEC}
% using semantic information limited to identifiers and comments,
% which may differ from the actual semantics (e.g. due to bugs).
%
%Some of the closest to our refactoring from the point of considering program semantics are~\cite{Kataoka:2001:ASP:846228.848644}, 
Kataoka et al. use
program invariants (found by the dynamic tool Daikon) to infer
%such that when a particular pattern of invariant
%relationships appears at a program point, a
whether specific refactoring are applicable~\cite{Kataoka:2001:ASP:846228.848644}. %The invariant detection tool called Daikon is used to
%dynamically infer the required invariants.
Notably, %the refacoring process relies on finding the required invariants, which
finding invariants is notoriously difficult especially
for real-world programs. Moreover, the technique is limited to a small number of refactorings and does not include
the elimination of deprecated instances.
In \cite{conf/sigsoft/GyoriFDL13}, Gyori et al. present the tool {\sc LambdaFicator} which
automates two pattern-based refactorings. The first refactoring converts
anonymous inner classes to lambda expressions. The second
refactoring converts for loops that iterate over Collections
to functional operations that use lambda expressions.
The {\sc LambdaFicator} tool~\cite{DBLP:conf/icse/FranklinGLD04} is available as a
NetBeans branch.



%% . However, because search-based refactoring is a novel
%% approach it has yet to be established which search techniques are most suitable
%% for the task. In this article we report the results of an empirical comparison of
%% simulated annealing, genetic algorithms and multiple ascent hill-climbing in search-based
%% refactoring. 


%% Kataoka et al. interpret program semantics to apply refactorings
%% \cite{Kataoka:2001:ASP:846228.848644}, but use dynamic test execution
%% rather than formal verification, and hence their transformation lacks
%% soundness guarantees.
%
%% Franklin et al. implement a pattern-based refactoring approach
%% transforming statements to stream queries~\cite{Gyori:2013:CGI:2491411.2491461}.
%% Their tool LambdaFicator~\cite{DBLP:conf/icse/FranklinGLD04} is available as a
%% NetBeans branch.
%We compared \tool against it in our experimental evaluation
%in Sec.~\ref{experiments-results}.
%
%% \paragraph{Heap Logics}
%
%% While many decidable heap logics have been developed recently, none are
%% expressive enough to capture operations allowed by the Java Collection
%% interface, operations allowed by the Java Stream interface as well as
%% equality between collections (for lists this implies that we must be able to
%% reason about both content of lists and the order of
%% elements)~\cite{DBLP:conf/cav/ItzhakyBINS13, DBLP:conf/cav/PiskacWZ13,
%% DBLP:conf/esop/BrainDKS14, DBLP:conf/popl/MadhusudanPQ11,
%% DBLP:conf/atva/BouajjaniDES12, DBLP:conf/lpar/DavidKL15}.  On the other
%% hand, very expressive transitive closure
%% logics~\cite{DBLP:conf/csl/ImmermanRRSY04} are not concise and easily
%% translatable to stream code.

Although it is guided by semantics, our techniques does not expect any
precomputed information such as logical well-formedness properties or
invariants. Instead, we make use of information that is already
available in the original program and Javadoc, namely code hints and
type information. Moreover, we explore the space of all potential
candidate programs by combining techniques from type-directed,
component-based and counterexample-guided inductive synthesis.


\section{Conclusion}

We conjecture that refactorings driven by the semantics of programs have
broader applicability and are able to address more complex refactoring
schemata in comparison to conventional syntax-driven refactorings, thereby
increasing the benefits of automated refactoring.  The space of possible
semantic refactoring methods is enormous; as an instance, we have presented
a method for refactoring iteration over Java collection classes based on
program synthesis methods.  Our experiments indicate that refactoring using
this specific instance is feasible, sound and sufficiently performant. 
Future research must broaden the evidence for our general hypothesis by
considering other programming languages, further, ideally more complex
refactoring schemata, and other semantics-based analysis techniques.

%\acks

% We recommend abbrvnat bibliography style.
\bibliographystyle{ACM-Reference-Format}
%\bibliographystyle{abbrv}
\bibliography{document}



\end{document}

%                       Revision History
%                       -------- -------
%  Date         Person  Ver.    Change
%  ----         ------  ----    ------

%  2013.06.29   TU      0.1--4  comments on permission/copyright notices

