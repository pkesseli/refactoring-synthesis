%-----------------------------------------------------------------------------
%               Template for OOPSLA
%               based on:
%               Template for sigplanconf LaTeX Class
%
% Name:         sigplanconf-template.tex
%
% Purpose:      A template for sigplanconf.cls, which is a LaTeX 2e class
%               file for SIGPLAN conference proceedings.
%
% Guide:        Refer to "Author's Guide to the ACM SIGPLAN Class,"
%               sigplanconf-guide.pdf
%
% Author:       Paul C. Anagnostopoulos
%               Windfall Software
%               978 371-2316
%               paul@windfall.com
%
% Created:      15 February 2005
%
%-----------------------------------------------------------------------------
\documentclass[runningheads,a4paper]{llncs}
%\documentclass[sigconf,authordraft]{acmart}
%\acmConference[ESEC/FSE 2017]{11th Joint Meeting of the European Software Engineering Conference and the ACM SIGSOFT Symposium on the Foundations of Software Engineering}{4--8 September, 2017}{Paderborn, Germany}
%\documentclass[10pt,numbers]{sigplanconf}
%\usepackage[1stsubmission]{oopsla2016}
%\usepackage[2ndsubmission]{oopsla2016}

%\usepackage[scaled]{helvet} % see www.ctan.org/get/macros/latex/required/psnfss/psnfss2e.pdf

\usepackage{microtype}
\usepackage{url}                  % format URLs
\usepackage{listings}          % format code
\lstset{
  mathescape, 
  language={Java},
  basicstyle=\footnotesize
}
\usepackage{enumitem}      % adjust spacing in enums
%\usepackage[colorlinks=true,allcolors=blue,breaklinks,draft=false]{hyperref}   % hyperlinks, including DOIs and URLs in bibliography
% known bug: http://tex.stackexchange.com/questions/1522/pdfendlink-ended-up-in-different-nesting-level-than-pdfstartlink

\usepackage{graphicx}
\usepackage{float,subfig}
\usepackage{xspace,framed}
\usepackage{colortbl}
\usepackage{calc}
\usepackage[ruled,vlined]{algorithm2e}

%\usepackage{algorithm}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{tikz}
\usepackage[justification=centering]{caption}
\usepackage{stmaryrd}
\usetikzlibrary{positioning, arrows, automata, shapes}
\usepackage{hhline}
\usepackage{pifont}
\usepackage{cite}
\usepackage{pdflscape} % Experiments table is landscape
\usepackage{longtable}
\usepackage{afterpage}
\usepackage{wasysym}

\usepackage[justification=centering]{caption}
\input{macros}

%\setlength{\belowcaptionskip}{-10pt}
\setlength{\textfloatsep}{1em}
\setlength{\dbltextfloatsep}{1em}
\setlength{\abovecaptionskip}{0.1em}
% \floatsep: space left between floats (12.0pt plus 2.0pt minus 2.0pt).
% \textfloatsep: space between last top float or first bottom float and the text (20.0pt plus 2.0pt minus 4.0pt).
% \intextsep : space left on top and bottom of an in-text float (12.0pt plus 2.0pt minus 2.0pt).
% \dbltextfloatsep is \textfloatsep for 2 column output (20.0pt plus 2.0pt minus 4.0pt).
% \dblfloatsep is \floatsep for 2 column output (12.0pt plus 2.0pt minus 2.0pt).
% \abovecaptionskip: space above caption (10.0pt).
% \belowcaptionskip: space below caption (0.0pt).

\allowdisplaybreaks

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% uncomment for extended version 
\newcommand*{\extended}{}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% The following oopsla2016 options are available:
%
% 1stsubmission   For the initial submission
% 2ndsubmission   For the 2nd submission
% final           For camera-ready

\begin{document}

%\copyrightdata{978-1-nnnn-nnnn-n/yy/mm} 
%\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

\title{Deprecated elimination with program synthesis}
%\subtitle{Subtitle Text, if any}
% double-blind submission
% single-blind only for Technical Research: http://icse2017.gatech.edu/technical-research-cfp
 % \authorinfo{Cristina David}
 %            {University of Oxford}
 %            {cristina.david@cs.ox.ac.uk}
 % \authorinfo{Pascal Kesseli}
 %            {University of Oxford}
 %            {pascal.kesseli@cs.ox.ac.uk}
 % \authorinfo{Daniel Kroening}
 %            {University of Oxford}
 %            {kroening@cs.ox.ac.uk}

\author{
\mbox{Cristina David}\inst{1} \and
Pascal Kesseli\inst{2} \and
Daniel Kroening\inst{2}}

\institute{University of Bristol, UK 
\and
  University of Oxford, UK}

%% \author{Cristina David}
%% \affiliation{University of Oxford}
%% \email{cristina.david@cs.ox.ac.uk}

%% \author{Pascal Kesseli}
%% \affiliation{University of Oxford}
%% \email{pascal.kesseli@cs.ox.ac.uk}

%% \author{Daniel Kroening}
%% \affiliation{University of Oxford}
%% \email{kroening@cs.ox.ac.uk}

\maketitle

\begin{abstract}
%
  Refactorings are structured changes to existing software that leave its
  externally observable behaviour unchanged.  Their intent is to improve
  readability, performance or other non-behavioural properties. 
  State-of-the-art automatic refactoring tools are {\em syntax}-driven and,
  therefore, overly conservative.  In this paper we explore {\em
  semantics}-driven refactoring, which enables much more sophisticated
  refactoring schemata.  As~an exemplar of this broader idea, we present
  an automatic refactoring tool that replaces uses of deprecated legacy APIs/libraries
  with the latest ones.
  Our refactoring procedure performs
  semantic reasoning and search in the space of possible refactorings using
  automated program synthesis.  Our experimental results support the
  conjecture that semantics-driven refactorings are more precise and are
  able to rewrite more complex code scenarios when compared to syntax-driven
  refactorings.
%
\end{abstract}

%\keywords{program refactoring, program synthesis, program verification}

%\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore, 
% you may leave them out
%\terms
%term1, term2

%% \keywords
%% Maintenance and reuse



\section{Introduction}

As a project evolves, there are certain fields, methods or classes
that the developers are discouraged from using in the future as
they've been superseded and may cease to exist in the future.
However, removing them directly would break the backward compatibility
of the project's API.  Instead, such elements can be tagged with the
\code{@Deprecated} annotation.  In general, when deprecating a
field/method/class, the \code{@deprecated} Javadoc tag is used in the
comment section to inform the developer the reason of deprecation and
what can be used in place.

%% \subsection{Deprecated example}

%% The {\em Deprecated} annotation in Java is used to mark program elements which
%% programmers are discouraged from using for various reasons such as future API
%% changes or security problems in the method. Usually API designers provide
%% programmers with recommendations about what they should use instead.

%% Even in the presence of such recommendations, the transformation of
%% existing code to the recommended format is not always straightforward,
%% as illustrated in Fig.~\ref{ex:deprecated-method}. In the example, we
%% make use of the \code{Date} class and we set the hour of the \code{Date} object to $10$.
%% However, the \code{getHours} method is deprecated and we must
%% use \code{Calendar.set} instead.


Even in the presence of such recommendations, the transformation of
existing code to the recommended format is not always straightforward,
as illustrated in Fig.~\ref{ex:deprecated-method-other}. In the example, we
make use of the \code{getHours} method of the \code{Date} class,
which is deprecated with the 
recommendation to use \code{Calendar.get(Calendar.HOUR\_OF\_DAY)} instead.
%In the example, we set the hour of the \code{Date} object to $10$.
However,
%% the 
%% \code{Date} constructor expects its year parameter to be an offset
%% from 1900, i.e. the year 2020 is expressed as 120.  This needs to be
%% transformed to 2020 when using \code{Calendar} API, as shown in the
%% example. Moreover,
the \code{Calendar} constructor is protected,
meaning that we must use \code{getInstance} to obtain a
\code{Calendar} object. Moreover, in order to be able to use this \code{Calendar} object for our purpose,
we must first set its time using the existing \code{date}.
We do this by calling \code{setTime} with \code{date} as argument.
%% followed by setting the date using \code{set}
%% and returning a Date object by invoking \code{getTime}.
%% Alternatively, the \code{GregorianCalendar} class may be used with
%% similar difficulties.
Only after all this set up, we can finally make use of the recommendation
\code{calendar.get(Calendar.HOUR\_OF\_DAY)}.

\begin{figure}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
void main(String[] args) {
  // Deprecated:
  int hour = date.getHours();
  
  // Should have been:
  final Calendar calendar = Calendar.getInstance();
  calendar.setTime(date);
  int hour = calendar.get(Calendar.HOUR_OF_DAY);
}
\end{lstlisting}
\caption{Deprecated method example.}
\label{ex:deprecated-method-other}
\end{figure}


While it is trivial for IDEs such as Eclipse or IntelliJ IDEA to
recognise the use of deprecated APIs and warn the programmer about it,
refactoring the code to a preferred API is significantly more
complex. Indeed neither Eclipse 4.15.0 nor IntelliJ IDEA 2020.2.2 make
any attempt to suggest a better alternative to the user. There is also
very limited support offered by the research community, mainly
focusing on replacing calls to deprecated methods by their
bodies~\cite{DBLP:conf/paste/Perkins05}. Consequently, the majority of
such refactorings are done manually, which is a costly,
time-intensive, and not least error-prone process.  This situation is
also a real issue for legacy code that makes use of deprecated APIs
that need to be replaced with latest APIs/libraries.

The main cause of difficulty when replacing deprecated instances lies
with the fact that such refactorings are based on semantics rather
than syntax. For illustration, let's refer back to the example in
Figure~\ref{ex:deprecated-method}.  A {\em syntax-driven refactoring}
addresses structural changes to the program requiring only limited
information about a program's semantics, whereas a {\em
  semantics-driven refactoring} requires detailed understanding of the
program semantics in order to be applied soundly.  Clearly, the
refactoring of the call to the deprecated \code{Date} constructor
falls into the latter category. %%, as we need to understand exactly

%\subsection{From the previous introduction:}
%% Refactorings are structured changes to existing software which leave its
%% externally observable behaviour unchanged.  They improve non-functional
%% properties of the program code, such as testability, maintainability and
%% extensibility while retaining the semantics of the program.  Ultimately,
%% refactorings can improve the design of code, help finding bugs as well
%% as increase development speed and are therefore seen as an integral part
%% of agile software engineering processes~\cite{DBLP:conf/xpu/Kerievsky04b,
%% Fowler1999}.

%% However, manual refactorings are a costly, time-intensive, and not least
%% error-prone process.  This has motivated work on automating specific
%% refactorings, which promises safe application to large code bases at low
%% cost.  We differentiate in this context between {\em syntax-driven} and {\em
%% semantics-driven} refactorings.  While the former address structural changes
%% to the program requiring only limited information about a program's
%% semantics, the latter require detailed understanding of the program
%% semantics in order to be applied soundly.  An example of a refactoring that
%% requires a semantics-driven approach is {\em Substitute Algorithm}, where an
%% algorithm is replaced by a clearer, but equivalent
%% version~\cite{Fowler1999}.
%
%AST-based constraints 
%
%% A syntax-driven approach is insufficient to perform such substantial
%% transformations.  Figure~\ref{ex:syntax-limits} illustrates this using an
%% example: Both loops in the code implement the same behaviour.  In order to
%% recognise this and apply {\em Substitute Algorithm}, pattern-based
%% approaches need explicit patterns for vastly different syntaxes implementing
%% the same semantics, which is infeasible for practical applications.

%% \todo{I've removed the reference to Move Field as it's a bit controversial given that
%% Steinmann uses it to explain that purely syntactic approaches are not enough.}

Notably, the limitations of syntax-driven refactorings have been observed
in several works, resulting in an emerging trend to incorporate more {\em semantic}
information into refactoring decisions, such as Abstract Syntax Tree (AST) 
type information,
further preventing compilation errors and behaviour changes
\cite{Steimann2011,Steimann2012Pilgrim,Steimann2011KollePilgrim}.
%% use constraints involving the abstract syntax tree type 
%% information in order to handle the {\em Move Field} (when a field
%% is used by another class more than the class on which it is defined)
%% of syntax-driven, e.g.  
%% An example 
%% of a refactoring that is well handled by the syntax-driven approach 
%% implemented using constraints over the program's abstract syntax tree
%% There is an emerging trend to incorporate more {\em semantic}
%% information into refactoring decisions, such as AST type information,
%% further preventing compilation errors and behaviour changes
%% \cite{Steimann2011}.

In this paper, we take a step further in this direction by proposing a
fully semantic refactoring approach for removing deprecated elements.
There is a very broad space of methods that are able to reason about
program semantics.  The desire to perform refactorings safely suggests
the use of techniques that overapproximate program behaviours.  As one
possible embodiment of semantics-driven refactoring, we leverage
software verification technologies with the goal of reliably
automating refactoring decisions based on program semantics.
%% , as in the
%% case of the {\em Substitute Algorithm} refactoring.
Our research
hypothesis is that semantics-driven refactorings are more precise and
can handle more complex code scenarios in comparison with
syntax-driven refactorings.

%% \paragraph{Demonstrator: Deprecated}

%% We use a particular refactoring as demonstrator for our idea.

\paragraph{Goal of the paper} 
Our goal in this paper is to design a fully automated refactoring
technique for eliminating deprecated fields, methods and classes. Our
technique will make use of Java library comments to find components
for seeding the refactoring. Then, it will use program synthesis to
generate code that is semantically equivalent to the original but does not use
the deprecated elements.

One interesting aspect when using a fully semantics-driven approach is
that it allows introducing the notion of {\em refactoring context}.
The refactoring context is the context (of the code to be refactored)
taken into consideration when looking for a refactoring. Varying the
context enables the user to control the generality of the refactoring.


For illustration, for the refactoring in Figure~\ref{ex:deprecated-method-other}...
\todo{hmm, what context do we consider for the standard library?}

\todo{Should we also discuss our choice of synthesis in the intro?}

%% In this paper, we are interested in refactoring Java code handing
%% collections through external iteration to use streams. Our refactoring
%% procedure is based on the program semantics and makes use of program
%% synthesis.

\paragraph{Contributions:}

\begin{itemize}

\item We propose a semantics based approach to eliminate uses of deprecated APIs. Our approach
  is iterative and counterexample based. One key insight is that, in each iteration, the refactoring problem can
  be encoded as the problem of verifying the safety of a program, which is then solved by fuzzing.

\item We introduce the concept of refactoring context. %% The refactoring context is different from the
  %% actual code to be refactored.
  Our refactoring technique generally starts 
  with no context and gradually increase the amount of context we take into consideration
  until a desirable refactoring is found.

\item We Implemented our technique in the tool ?? and used it to
  refactor deprecated instances in X open source projects.
  
\end{itemize}  

%
%% \begin{itemize}
%% %
%% \item We present a program synthesis based refactoring procedure for Java
%% code that handles collections through external loop iteration.
%% %
%% \item We have implemented our refactoring method in the tool \tool. Our
%% experimental results support our conjecture that semantics-driven
%% refactorings are more precise and can handle more complex code scenarios
%% than syntax-driven refactorings.
%% %
%% \end{itemize}



\section{Overview of our approach} \label{sec:approach}

Our technique is semantics-based and makes use of advances in the
field of program synthesis. In particular, we make use of the general
structure of Counterexample Guided Inductive Synthesis (CEGIS), but
instead of using symbolic execution to both generate and verify
candidate refactorings, we use fuzzing, as described later in this
section.  Our synthesis method is also component based, meaning that
it uses components from a given library to generate new code.  In the
rest of this section, we describe how we build the components library
followed by presenting the actual refactoring synthesis.
%%Our technique for refactoring deprecated instances (e.g. fields, methods, classes) has two big steps, as described next.

\paragraph{{\bf Input to our method}}
We expect as input the original deprecated code \var{Orig} with inputs
$\vec{x}$, as well as access to the library where the
field/method/class has been deprecated. We need the latter to seed the
components library.  Depending on the user's intention we may also
take into consideration some amount of context (of the location where
the deprecated element is found) when searching for a refactoring.

\paragraph{{\bf Seed the components library}}
% Our synthesis engine is component based, meaning that, in order to generate new code, it makes use of a library of components.
For each required refactoring, we start by building the components library.
%Initially, we build our components library for the actual synthesis process. 
In general, when deprecating a field/method/class, the
\code{@deprecated} Javadoc tag is used in the comment section to
inform the developer the reason of deprecation and what can be used in
place. We pick hints from the comments accompanying the
\code{@deprecated} tag.

% Other github projects that have already been ported.
\todo{Maybe we can also collect sketches as especially the unit tests will provide us with more than just the name of the replacement.}
% As opposed to the comments in libraries, the unit tests are syntactically valid

As an example, the \code{getHours} method in class \code{Date} used in Figure~\ref{ex:deprecated-method-other} is accompanied by the following comment:

\begin{lstlisting}[mathescape=true,showstringspaces=false]
/**
 * Returns the hours represented by this <code>Date</code>
 * object as an integer between 0 and 23.
 *
 * @return the hours represented by this date object.
 * @deprecated Use Calendar instead of Date, and use get(Calendar.HOUR_OF_DAY)
 * instead.
 * @see Calendar
 * @see #setHours(int)
 */  
\end{lstlisting}

%% /**
 %% * Creates a new Date Object representing the given time.
 %% *
 %% * @deprecated use <code>new GregorianCalendar(year+1900, month,
 %% * day)</code> instead.
 %% * @param year the difference between the required year and 1900.
 %% * @param month the month as a value between 0 and 11.
 %% * @param day the day as a value between 0 and 31.
 %% */


This will result in adding \code{``get(Calendar.HOR\_OF\_DAY)''} to our library.
In certain situations, the seeding of the component library may require additional work.
For instance, for the example in Figure~\ref{ex:deprecated-method-other}, we need to also provide a way of obtaining
a \code{Calendar} object. Thus, we add \code{Calendar.getInstance()}. The seeding algorithm is provided in
Figure~\ref{alg:seeding}.

\begin{figure}
\begin{algorithm}[H]
\SetAlgoLined
\KwResult{Component library}
 Add instructions suggested under the @deprecated tag\;
 use-set = all classes suggested for use\;
 \For{c $\in$ use-set}{
   Add public constructors of c\;
   Add public methods returning an object of class c\;
   %%use-set = use-set $\cup$ classes suggested for use\;
 }
\end{algorithm}
 \caption{Component library seeding algorithm}
\label{alg:seeding}
\end{figure}



As future work we aim to also collect components and sketches from the  unit tests for the updated library.
 
\paragraph{{\bf Automatically generating the desired refactoring}} For this purpose, we use a counterexample-guided iterative process that enables us to keep refining a candidate refactoring until we are happy with it. This process consists of two phases, described next:
  \begin{itemize}
  \item[{\bf Phase 1:}] Given a fixed set of inputs $In$, find a refactoring that works for $In$. For this purpose, we encode   
    the synthesis problem as a verification problem that can be solved by fuzzing. We discuss this problem encoding in
    Section~\ref{sec:encoding}. The found refactoring is called a candidate.
  \item[{\bf Phase 2:}] Given the candidate synthesised at the previous step, verify whether it is indeed a correct refactoring.
    Again, we answer this question by encoding it as a software verification problem to be solved by fuzzing (see Section~\ref{sec:encoding}).
    If an input for which the candidate isn't observationally equivalent to the original code is found, then
    we return to the previous step and add this input to the set $In$. Otherwise we have found a correct refactoring and we are done.
  \end{itemize}

\todo{Run through the motivational example: candidates, counterexamples etc.}  



\subsection{Problem encoding}\label{sec:encoding}

In this section, we discuss our encoding of the problem solved in each
of the two phases of the synthesis process.  We refer to the original
code as \var{Orig(\vec{x})} and the final refactored code as
\var{Refactor(\vec{x})}, where we assume that both \var{Orig} and
\var{Refactor} have the same inputs \var{\vec{x}}. Moreover,
we use \var{Candidate(\vec{x})} to refer to a candidate refactoring.

%% We encode the refactoring problem as a verification problem that can be solved by
%% fuzzing. We next describe the verification and synthesis phases in a CEGIS module,
%% where \var{Orig} and \var{Refactor} denote the original and refactored code,
%% respectively.

\paragraph{The verification phase} For the verification phase, we are provided with a candidate
refactoring and we must check whether there exists any input
\var{\vec{x}} for which the original code and the candidate
refactoring are not observationally equivalent.  To do this, we build
the following \code{Verify} method, which given some input
\var{\vec{x}}, asserts that the two programs are equivalent for
\var{\vec{x}}.

\begin{lstlisting}[mathescape=true,showstringspaces=false]
Verify(x) {
  assert(equivalent(Orig(x), Candidate(x)));
}
\end{lstlisting}

In other words, answering the initial question posed by the verification
phase is reduced to checking the safety of this method: if
\code{Verify} is safe (i.e. the assertion is not violated) for any
input \var{\vec{x}}, then there is no input that can distinguish
between the original and the candidate refactoring meaning that this
is indeed a sound refactoring. However, if \code{Verify} is not safe,
then we want to be able to obtain a counterexample input
\var{\vec{x_{cex}}} for which the assertion fails. This counterexample
will be provided to the synthesis phase and used to refine the current
candidate. We check the safety of \code{Verify} with coverage-guided
fuzz testing. While this means that we may fail to find a
distinguishing input when one does exist, we discuss later in the
paper our reasons for choosing to use fuzzing over other sound
verification techniques.

A core part of the verification phase and the whole synthesis process
is the \var{equivalent} procedure, which checks that the original code
and a candidate refactoring are equivalent for a given input.
Naively, this would be checked by comparing the results returned by the
\var{Orig} and \var{Candidate}. However, that is not enough as
we must also consider the heap representation. We will discuss this in
Section~\ref{sec:equiv}.

%% notion of program equivalence.  While this is undecidable in
%% general, our synthesis procedure in the verification phase this problem is restricted to
%% checking that \var{Orig} and \var{Candidate} are equivalent for a .


%% The fuzzer will find an input for which the original and refactored code
%% produce a different result.

\paragraph{The synthesis phase} For the synthesis phase, we are provided with a
a finite set of input examples $\{x_1 \cdots x_n\}$ and we need to find a candidate refactoring
that is observationally equivalent to the original program for these inputs.
For this purpose, we construct the following \code{Synthesise} method, which
takes the refactored code \var{Candidate} as input.

\begin{lstlisting}[mathescape=true,showstringspaces=false]
Synthesise (Candidate) {

  if (equivalent(Orig($x_1$), Candidate($x_1$)) && ...
  && equivalent(Orig($x_n$), Candidate($x_n$)))
   assert(false);
}
\end{lstlisting}

Again, we reduce the problem to be solved in the synthesis phase to
the problem of checking the safety of the \code{Synthesise} method,
which we do by fuzzing.
The fuzzer will find an input \var{Candidate} that fails the assertion,
meaning that it returns the same output as \texttt{Orig}
on the finite set of inputs \var{x_1, \cdots, x_n}.


%% - Performing the synthesis. Complex bit: synthesising method invocations for methods that contain loops.

%% \begin{enumerate}
%% \item We seed the templates/snippets for the synthesis library using the following two strategies:
%%   \begin{itemize}
%% \item Use deprecated block messages.
%% \item Use the unit tests for the new library. As opposed to the comments in libraries,
%%   the unit tests are syntactically valid.
%%   \end{itemize}

%% \item Use the seeded templates to generate the refactoring.
%%   \begin{itemize}
%% \item Look at checking equivalence in the presence of loops.
%%   \end{itemize}
%%   \end{enumerate}

\subsection{Checking program equivalence for a certain input}\label{sec:equiv}

%\paragraph{Checking heap equivalence}

In Section~\ref{sec:encoding}, we use \var{equivalent(Orig(x),
  Candidate(x))} to denote equivalence checking for \var{Orig} and
\var{Candidate} on concrete input \var{x}.
In this section, we provide details on how we check this equivalence.


%% First, this function needs
%% to check whether for input \var{x}, the outputs of the original and
%% candidate refactored programs are the same.  Moreover, any realistic
%% Java program makes modifications to the heap. Consequently,
%% \var{equivalent} must check that heap is being handled in the same
%% manner in both programs.


We'll generally refer to the original code as \var{P_1} and the refactored one
as \var{P_2}. We further use:
\begin{itemize}
\item \var{loadedClasses(P)} to obtain the set of classes loaded by the class loader
  in which the execution of \var{P} is performed.
\item \var{liveVars(P)} returns the set of variables that are live
at the end of the $P$. %% Thus, \var{liveVars(P_1)} gives us the
%% variables that have been updated in the original code \var{P_1} and are
%% live at the end of \var{P_1}.
\item \var{staticFields(C)} returns
  the set of static fields of a class \var{C}.
\end{itemize}  

\begin{example}\label{ex:defs}
  For our running example in Figure~\ref{ex:deprecated-method},
  \var{P_1} is represented by the following line of code:

\begin{lstlisting}[mathescape=true,showstringspaces=false]
  Date date = new Date(120, 12, 30);
\end{lstlisting}

Whereas \var{P_2} is denoted by:

\begin{lstlisting}[mathescape=true,showstringspaces=false]
  final Calendar calendar = Calendar.getInstance();
  calendar.set(2020, 12, 30);
  final Date date = calendar.getTime();
\end{lstlisting}
  
Then, we have:
\[
\begin{aligned}[t]
  \var{liveVars(P_1)} &= \{date\}\\
  \var{liveVars(P_2)} &= \{calendar, date\}\\  
  \var{loadedClasses(P_1)} &= \{Date\} \\
  \var{loadedClasses(P_2)} &= \{Calendar, Date\} \\  
  \var{staticFields(Date)} &= \emptyset\\
  \var{staticFields(Calendar)} &= \{DATE, YEAR, \cdots\}  
\end{aligned}
\]
\end{example}


In order to extract the value assigned to a variable \var{v} by the execution of \var{P} on a specific input \var{x},
we will use the notation \var{E[P(x)](v)}. Essentially, if we consider the trace generated by executing \var{P(x)},
then \var{E[P(x)]} maps each variable defined in \var{P} to the latest value assigned to it by this trace.


Next, we define the notion of equivalence with respect to a concrete input \var{x}.

\begin{definition}[Program equivalence with respect to a concrete input \var{x} {\bf[partial]}]\label{def:prog-equiv}
  Given two programs \var{P_1} and \var{P_2} and concrete input \var{x},
  we say that \var{P_1} and \var{P_2} are equivalent
  with respect to \var{x}, written as \var{equivalent(P_1(x), P_2(x))}
  if and only if the following conditions hold:

\[
    \begin{aligned}
      & (1)~ \forall v\in liveVar(P_1)\cap liveVar(P_2). equivalent(E[P_1(x)](v), E[P_2(x)](v))\\
%& (2) equivalent(aliasEquivClass(liveVar(P_1)), aliasEquivClass(liveVar(P_2)))      
& (2)~  \forall C \in loadedClasses(P_1) \cap loadedClasses(P_2).\forall f \in staticFields(C).\\
  &  ~~~~~ equivalent(E[P_1(x)](f), E[P_2(x)](f))
    %%   throws an exception and   $equiv(exception(R_1), exception(R_1))$. 
  %% \item \var{R_1} doesn't throw an exception and $equiv(R_1,R_2)$ and
   %% $\forall f_i \in getStatic(class(R_1)) \wedge g_i \in getStatic(class(R_2)). equiv(f_i,g_i)$.
    \end{aligned}
    \]
   
  \end{definition}

The above definition says that in order for \var{P_1} and
\var{P_2} to be equivalent with respect to input \var{x}, any variable
that is live at the end of both \var{P_1} and \var{P_2} must be
assigned equivalent values by the executions of \var{P_1} and
\var{P_2} on \var{x}, respectively.
Additionally, for any class that
is being loaded by the class loader of both \var{P_1} and \var{P_2},
all the static fields must again be assigned equivalent values by the
two executions. %% Note that we use the notation \var{v/P(x)} to denote the
%% value assigned to \var{x} by the execution of \var{P} on input \var{x}.
Note that, as mentioned in its name, Definition~\ref{def:prog-equiv} only partially
defines the equivalence of \var{P_1} and \var{P_2} on input \var{x}. For now
we will ignore this and get back to it later in the section.

\begin{example}\label{ex:equiv}
  When applying Definition~\ref{def:prog-equiv} to \var{P_1} and \var{P_2} given in Example~\ref{ex:defs},
  the following conditions must hold:
\[
    \begin{aligned}
& (1)~ \forall v\in \{date\}. equivalent(E[P_1(x)](v), E[P_2(x)](v))\\
& (2)~  \forall C \in \{Date\}.\forall f \in staticFields(C).equivalent(E[P_1(x)](f), E[P_2(x)](f))
    %%   throws an exception and   $equiv(exception(R_1), exception(R_1))$. 
  %% \item \var{R_1} doesn't throw an exception and $equiv(R_1,R_2)$ and
   %% $\forall f_i \in getStatic(class(R_1)) \wedge g_i \in getStatic(class(R_2)). equiv(f_i,g_i)$.
    \end{aligned}
    \]

    Given that class \var{Date} has no static fields, the second condition is trivially met. Then, in order for the two portions of code to be
    equivalent with respect to an input \var{x}, the objects assigned to variable \var{date} by the execution of  \var{P_1(x)} and \var{P_2(x)}
    must be equivalent. We will discuss checking equivalence of two objects in two distinct executions next.
    
\end{example}

\todo{define $equivalent(E[P_1(x)](v), E[P_2(x)](v))$}.

\paragraph{Preserving aliasing}
When expressing the equivalence relation between \var{P_1} and \var{P_2}, we intentionally missed one important aspect,
namely aliasing. To understand the problem let's look a the following example, which denotes a slightly
modified version of the running example.

\begin{example}\label{ex:aliasing}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
  Date date1 = new Date(120, 12, 30);
  Date date2 = new Date(120, 12, 30);  
  
  final Calendar calendar = Calendar.getInstance();
  calendar.set(2020, 12, 30);
  Date date1 = calendar.getTime();
  Date date2 = date1;
\end{lstlisting}

For the code above, we will refer to the first two lines denoting the
original deprecated code as \var{P_3}, and the rest, denoting the
refactored code, as \var{P_4}.  We note that, as opposed to the
running example, \var{P_3} defines two variables \var{date1} and
\var{date2}, both assigned a \var{Date} object created by calling the
\var{Date} constructor with identical arguments.
Conversely, in \var{P_4}, \var{date1} and \var{date2} are aliases, i.e. they point to the same
memory location.

Note that, according to Definition~\ref{def:prog-equiv}, given an input \var{x}, \var{P_3} and \var{P_4} are equivalent with respect to \var{x}.
\todo{I should use a concrete input here.}
So, everything looks good until now. Let's however, assume that the following code
is used after \var{P_3/P_4}, corresponding to whether we refer to the original or refactored code.

\begin{lstlisting}[mathescape=true,showstringspaces=false]
  date1 = new Date(120, 10, 30);
\end{lstlisting}

Our intention is to execute the whole code, including this additional line, on input \var{x}.
If \var{P_3} and \var{P_4} were indeed semantically equivalent with respect to input \var{x},
then we would expect \var{date1} and \var{date2} to have the same value at the end of both
executions, respectively. However, this is not the case.
In the original code, using \var{P_3}, \var{date2} will be assigned an object
denoting the date ``30/12/2020'', whereas in the refactored code,
\var{date2} will correspond to the date ``30/10/2020''. This is due to the fact that,
in \var{P_4}, \var{date1} and \var{date2} are aliases. Then, when the object referenced by
\var{date1} was changed to refer to the date denoting ``30/10/2020'', this also affected \var{date2}.
Thus, \var{P_3} and \var{P_4} are not semantically equivalent for input \var{x}.
\end{example}  

Intuitively, any aliases between live variables at the end of the original code should also
be present at the end of the refactored code. For this purpose, we use the notation
\var{aliasEquivClass(V)} which returns the set of all equivalence classes induced over the
set of variables \var{V} by the aliasing relation.  
Notably, the same aliasing equivalence relation must also hold over the
static fields of the classes loaded by both programs.


\begin{example}
For \var{P_1} and \var{P_2}, there are no aliases, therefore:
\[
\begin{aligned}[t]
  \var{aliasEquivClass(liveVar(P_1))} &= \emptyset\\
  \var{aliasEquivClass(liveVar(P_2))} &= \emptyset
\end{aligned}
\]
%
However, for \var{P_3} and \var{P_4} we have:
\[
\begin{aligned}[t]
  \var{aliasEquivClass(liveVar(P_3))} &= \emptyset\\
  \var{aliasEquivClass(liveVar(P_4))} &= \{\{date1, date2\}\}
\end{aligned}
\]
In \var{P_4}, the alising relation induces one equivalence class, namely \var{\{date1, date2\}}.

\end{example}
  
Next, we adjust Definition~\ref{def:prog-equiv} to capture the aliasing aspect.

\begin{definition}[Program equivalence with respect to a concrete input \var{x} {\bf[complete]}]\label{def:prog-equiv}
  Given two programs \var{P_1} and \var{P_2} and concrete input \var{x},
  we say that \var{P_1} and \var{P_2} are equivalent
  with respect to \var{x}, written as \var{equivalent(P_1(x), P_2(x))}
  if and only if the following conditions hold:

\[
    \begin{aligned}
      & (1)~ \forall v\in liveVar(P_1)\cap liveVar(P_2). equivalent(E[P_1(x)](v), E[P_2(x)](v))\\
& (2)~ \forall v_1,v_2 \in liveVar(P_1) \cap liveVar(P_2). aliases(P_1, v_1, v_2) \Rightarrow aliases(P_2, v_1,v_2)\\      
& (3)~  \forall C \in loadedClasses(P_1) \cap loadedClasses(P_2).\forall f \in staticFields(C).\\
      &  ~~~~~ equivalent(E[P_1(x)](f), E[P_2(x)](f))\\
      & (4)~\forall f_1,f_2 \in staticFields(loadedClasses(P_1) \cap loadedClasses(P_2)).\\
      & ~~~~~ aliases(P_1, f_1, f_2) \Rightarrow aliases(P_2, f_1,f_2)
    %%   throws an exception and   $equiv(exception(R_1), exception(R_1))$. 
  %% \item \var{R_1} doesn't throw an exception and $equiv(R_1,R_2)$ and
   %% $\forall f_i \in getStatic(class(R_1)) \wedge g_i \in getStatic(class(R_2)). equiv(f_i,g_i)$.
    \end{aligned}
    \]
   
  \end{definition}

where, given a program \var{P}, variables \var{v_1} and \var{v_2} are aliases, i.e. \var{aliases(P, v_1, v_2)} holds,
if and only if they are in the same equivalence class induced by the aliasing relation,
  i.e. \var{aliasEquivClass(\{v_1,v_2\}) = \{\{v_1,v_2\}\}}.

  For the fourth condition, we abuse the notation to use \var{staticFields} over a set of classes, rather than just one class.
  The objective is to return the set of all static fields defined in all the classes in the set of classes taken as argument.
  
\todo{revise the rest.}
\todo{also add an example where static fields are changed.}

Given the potential use of aliases, we will use a Hash table to
associate a symbolic id to each pointer variable such that two
variable share the same id if and only if they are aliases.
%% Then, we can check whether the set of aliases is preserved in the
%% refactored program. For instance, if \texttt{obj1} and \texttt{obj2}
%% are aliases in the original program, then they must be aliases also
%% in the second program.
\todo{check exactly what this is used for.}

Note on aliasing checking:
Everything that is part of our comparison is in the isolated class loader.
For instance user defined types will usually be located in the isolated
class loader, enabling the comparison.
However, what do we do about wrapper object aliasing?
For anything outside the class loader, we use reference equality.
\todo{example?}

We execute the two programs on the given input and then compare the
result for equivalence. The two programs are equivalent with respect to
the given input if one of the conditions below are fulfilled: 
\begin{enumerate}
\item They throw the same exception.
\item They return equivalent values and all the static fields in the two corresponding classes
  are respectively equivalent.
\end{enumerate}  

Let's refer to the two programs as \var{P_1} and \var{P_2}, and the corresponding execution results
as \var{R_1} and \var{R_2}. We use $class(R)$ to get the class of object \var{R} and
$getStatic(C)$ to retrieve the static fields of \var{C}. Then, we provide the definition
for program equivalence on input \var{i} as follows:

\begin{definition}[Program equivalence with respect to a concrete input]
  Given the results \var{R_1} and \var{R_1} of executing \var{P_1} and \var{P_2}
  on the input \var{i}, respectively, we say the \var{P_1} and \var{P_2} are equivalent
  with respect to \var{i} if and only if one of the following holds:

  \begin{itemize}
  \item \var{R_1} throws an exception and   $equiv(exception(R_1), exception(R_1))$. 
  \item \var{R_1} doesn't throw an exception and $equiv(R_1,R_2)$ and
    $\forall f_i \in getStatic(class(R_1)) \wedge g_i \in getStatic(class(R_2)). equiv(f_i,g_i)$.
    \end{itemize}
    
  \end{definition}

  
Next, we define equivalence between two objects, denoted above by \var{equiv(R_1,R_2)}.

Equivalence classes induced by the aliasing relation need to be preserved by the
refactored program.



%% Aliasing check: checks whether the two given objects have the same aliasing ID, and thus
%%    alias with the same objects on their respective heaps.

%%    What do you assign id's to? I'm trying to figure out whether this is too strict?
%%    Basically, equivalence classes induced by the aliasing relation need to be preserved,
%%    but they may not have the same representative ID.

%% You compare execution results:
%% - do you just look at the returned object?

%% Equivalent execution results
%% - returned value
%% - static fields of the corresponding classes

%% Equivalent objects
%% - ObjectIdComparator
%% - IsAliasingEquivalent

%% State: static fields of all classes, stack vars, follow object pointers, thread locals?, equivalence classes induced by the aliasing relation must be preserved
%% - touch the same vars
%% - all touched vars correspond to equivalent objects
%% - 2 graphs are isomorphic

%% 2 obj are equal if all their fields are equal
%% 2 primitive types are equal if they are the same value

%% ============

%% a1 = new Integer(1);
%% b1 = new Integer(1);

%% vs

%% a2 = new Integer(1);
%% b2 = a2;




\subsubsection{Loaded classes}

One of the potential issues when checking equivalence of two program
is the treatment of loaded classes. In particular, one program might
load more classes than the other, but still have the exact same effect
as the other one. This can happen for instance if one program calls a
helper method from a class that needs to be loaded, whereas the other
program inlines the same method, thus avoiding loading the class.  Our
assumption is that loadeding and initialization don't perform any
changes outside of the observable state already checked by the
existing equivalence check.  While this assumption is generally safe
to make, there might be some cases when this is not the case, e.g. the
class initializer might print something on the screen. For now, we
don't handle these cases.

%% A class is initialized when a symbol in the class is first used. When
%% a class is loaded it is not initialized.

\todo{give example}



Discuss different types of fuzzing and the one that we use.
\todo{Double check with Pascal what he uses.}

\section{Algorithm}

\todo{Write description of the algorithm}

\section{Program fuzzing}

In order to generate programs, we make use of the fuzzing technique described
in~\cite{DBLP:conf/issta/PadhyeLS19} called JQF.  This technique is
coverage-guided, which means that it uses lightweight program
instrumentation to trace the code coverage reached by each generated
input that is fed to the program under test.  Basically, the program
is continuously executed with randomly generated inputs. However,
instead of generating inputs from scratch, coverage-guided fuzzers
evolve a set of saved inputs. If a new input leads to an increase
in code coverage, it is saved for subsequent evolution.

In our setting, the randomly generated inputs are programs.
This is a difficult setting for fuzzing because programs are
highly structured, whereas fuzzers often work with unstructured inputs
that can be generated via byte-level mutations such as bit flips.

JQF is designed to handle structured inputs, where inputs of type \code{T}
are generated by a backing \code{Generator<T>}.
While JQF provides a library of such generators, we manually write our own.
Essentially, our generator describes the grammar corresponding to the
programs to be synthesised.
JQF never generates the same exact program twice. However it may generate many
syntactically different, but semantically equivalent ones.
Next, we discuss a few techniques that we use to reduce the number of
generated programs that are semantically equivalent.

\subsection{Reduction of semantically equivalent programs}

\section{Guarantees}

\paragraph{Discussion on soundness} Given that we rely on fuzzing, we can't guarantee that the
refactoring works for all possible inputs. However, it is well suited
to the particular scenarios for which we designed our technique,
IDE integration where the refactoring is presented as a suggestion to the programmer,
or automated pull requests to be approved by the developers.
%% where
%% continuous integration practices are in place. In particular, once our
%% technique has found a possible refactoring, we sumit a pull request
%% that needs to be approved by other developers.

In order to fully guarantee the soundness of the refactorings proposed
by our technique, we would have to use a sound verification technique
in the verification phase mentioned earlier. However, such a technique
would require symbolic execution, which is notoriously difficult for
real-world programs due to features such as loops, library functions,
complex data structures. The most successful such verification
techniques are either bounded (i.e. check that an erroneous state
cannot be reached within a bounded number of loop unrollings) or
require user input in the form of loop invariants. While the former
class of techniques provides limited soundness guarantees, the latter
requires intricate help from the user.  In fact, we are not aware of
any sound and automatic symbolic verification method that can handle
the kind of code we are interested in.

Discuss tradeoff: symbolic execution is expensive; programming
languages evolve faster than verification techniques and therefore
many new features are not supported by their front ends (and/or
backends depending on how complex the new feature is); even after
translating the code into a logical formula, calls to solvers are
expensive.

\section{Discussion on completeness}



\section{Some research questions}

What if the new method doesn't maintain observational equivalence?
TODO: Check existing projects to see how many do preserve equivalence.
For the rest, is there a notion of partial equivalence that ensures the equivalence
for the new projects minus the differences introduced by the new function.

How easy is for the fuzzer to handle such structured inputs as we need in the
synthesis phase?


\subsection{For the experimental evaluation}
\begin{itemize}
\item Pick libraries that have deprecated instances.
\item Pick users of these libraries (i.e. open source projects that are actively maintained).
\item Make pull requests and see how many get merged.
\end{itemize}  

\section{Context-sensitive vs. context-insensitive refactoring}

\paragraph{Context-insensitive refactoring}
We consider different refactoring options. The first and most simple
one is the so called ``context-insensitive'' refactoring, where we
find a refactoring for the deprecated code that works irrespective of
context. This means that, once such a refactoring is found, it can be
used to replace all the uses of the deprecated code, e.g. a deprecated
method invocation will be replaced with the same refactored code
irrespective of the actual parameters or rest of the state at the call
site.

For instance, if we want to refactor the call to method
\texttt{toRefactor} in the code below, then we search for a refactoring that is
observationally equivalent to the given method irrespective of the
context of the call.

\begin{lstlisting}[mathescape=true]
class NoContext {
  int x;

  public double toRefactor(int y, int z) {
    return (double) x + y + z;
  }
}
\end{lstlisting}
 
This means that the state that we can vary in order to check for
observational equivalence includes \texttt{x, y} and \texttt{z}.

\paragraph{Context-sensitive refactoring}
The refactoring context consists of the context where the code to be refactored
is placed. For instance, in the snippet below, if we are trying to refactor the call to the deprecated
function \texttt{f}, then the context gives us the valuation $[\texttt{x}\mapsto 1]$ for the function's argument. 

\begin{lstlisting}[mathescape=true]
  int x = 1;
  A a = new A();
  
  a.f(1)
\end{lstlisting}
    
We now look at the possibility of considering the refactoring context
when searching for a refactoring. This gives us the option of starting
with very little context and gradually increasing it until finding a
refactoring. \todo{Adjust this based on what the experiments do.}

The other option is to find a refactoring that takes into consideration
the calling context. For instance, in the code below we have two
calls to \texttt{toRefactor}, one in method \texttt{foo} and one in
method \texttt{bar}. When considering the calling context, we have to
find two different refactorings, one for each of the method calls.
For the call in \texttt{foo}, the state that we need to consider for observational
equivalence contains \texttt{ctx} and \texttt{a}, whereas for the call in method
\texttt{bar} it contains \texttt{ctx, a, b, c, d} and \texttt{e}.

\begin{lstlisting}[mathescape=true]
  class Context1 {
    NoContext ctx = new NoContext();

    public double foo(int a) {
      return ctx.toRefactor(a, a);
    }
  }

 

  class Context2 {
    NoContext ctx = new NoContext();

    int d;
    int e;

    public double bar(int a, int b, int c) {
      return ctx.toRefactor(a, b + c + d + e);
    }
  }
\end{lstlisting}


%% Fuzzing:

%% someNoContext.x = x_*;

%% someNoContext.toRefactor(y_*, z_*);

%% Possible follow-up:
%% - if we have a sizeable codebase, the user might have to do 1,2 deprecated
%% refactorings and then the synthesisers can use the PRs done by the user
%% to seed the synthesiser and do the other thousands of refactorings
%% automatically.

\section{Implementation}

\subsection{Instrumentation}

The goal of our instrumentation is to execute a program candidate in
the same context as the original, deprecated method. The original
method can affect the program state by virtue of its return value,
field assignments in the case of instance methods, and static field
assignments. In order to account for these effects, our
instrumentation passes a reference to the original method's object
instance, if present, as an argument to the program candidate.
An example of this is presented in
Fig.~\ref{ex:side-effects-instrumentation}.

\begin{figure}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
// Redundant snippet:
Date today;
Date tomorrow;
  
void init(int year, int month, int day) {
  // Original:
  this.setDates(year, month, day);

  // Instrumented:
  Program.of(0xabcd).execute(year, month, day, this);
}
  
@Deprecated
private void setDates(int year, int month, int day) {
  final Calendar calendar = Calendar.getInstance();
  calendar.set(year, month, day);
  this.today = calendar.getTime();
  calendar.add(Calendar.DAY_OF_MONTH, 1);
  this.tomorrow = calendar.getTime();
}
\end{lstlisting}
\caption{Deprecated side-effects instrumentation.}
\label{ex:side-effects-instrumentation}
\end{figure}

Fig.~\ref{ex:date-instrumentation} illustrates an example where no
such relevant instance object exists and thus only the original
arguments are passed as arguments into the program candidate.

\begin{figure}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
// Redundant snippet:
static void main(String[] args) {
  // Original:
  Date date = new Date(120, 12, 30);

  // Instrumented:
  Date date = Program.of(0xabcd).execute(120, 12, 30);
}
\end{lstlisting}
\caption{Deprecated `Date' instrumentation.}
\label{ex:date-instrumentation}
\end{figure}

\section{Semantically different refactorings}


\begin{figure}
\begin{lstlisting}[mathescape=true,showstringspaces=false]
void main(String[] args) {
  // Deprecated:
  Date date = new Date(120, 12, 30);
 
  // Should have been:
  final Calendar calendar = Calendar.getInstance();
  calendar.set(2020, 12, 30);
  final Date date = calendar.getTime();

  // Or:
  final Date date = new GregorianCalendar(2020, 12, 30)
                      .getTime();
}
\end{lstlisting}
\caption{Deprecated method example.}
\label{ex:deprecated-method}
\end{figure}


Sometimes, the deprecated and the new features are not semantically
equivalent on the entire domain. Reasons for this might be that a bug
was fixed, a certain functionality was improved, or simply the fact
that the deprecated feature is only expected to be used on restricted
parts of the input domain. In such a case, the deprecated and the new
feature may not be semantically equivalent on the entire input domain.

For illustration, let's consider the example in Figure~\ref{ex:three-dates}.
In the example, we make use of the constructor \code{new Date(year, month, day)}, 
which is deprecated with the 
recommendation to use the \code{Calendar} class instead.
The refactoring is not trivial given that the 
\code{Date} constructor expects its year parameter to be an offset
from 1900.  This needs to be
transformed by adding 1900 when using \code{Calendar} API, as shown in the
example. Moreover, as already seen in the motivational example in  Figure~\ref{ex:deprecated-method-other},
the \code{Calendar} constructor is protected,
meaning that we must use \code{getInstance} to obtain a
\code{Calendar} object.
Alternatively, the \code{GregorianCalendar} class may be used with
similar difficulties.
In the example, we use \var{date1}, \var{date2} and \var{date3} to denote the three distinct ways of constructing a date.

%% For illustration, let's consider the three distinct ways of
%% constructing a date captured in Figure~\ref{ex:three-dates} and
%% denoted by \var{date1}, \var{date2} and \var{date3}.

\begin{figure}
  \begin{lstlisting}[mathescape=true,showstringspaces=false]
  // Deprecated:
  Date date1 = new Date(year, month, day);

  // Should have been:
  Calendar calendar = Calendar.getInstance();
  calendar.set(1900 + year, month, day, 0, 0, 0);
  calendar.set(Calendar.MILLISECOND, 0);
  Date date2 = calendar.getTime();
    
  // Or:
  Date date3=new GregorianCalendar(1900+year,month,day).getTime();
  \end{lstlisting}
\caption{Deprecated `Date' example.}
\label{ex:three-dates}
\end{figure}

%% In the example, \var{date1} uses the deprecated
%% \var{Date(year, month, day)} constructor, whereas \var{date2} and
%% \var{date3} make use of the recommended \var{Calendar} and
%% \var{GregorianCalendar} classes.
Notably, the ways in which \var{date2} and \var{date3} are computed
represent a valid refactoring for the piece of code computing
\var{date1}. However, when we provide this example to our
verifier (as described in Section~\ref{X}), we obtain the following
counterexample:

  \begin{lstlisting}[mathescape=true,showstringspaces=false]
    int year = -89412298;
    int month = 1439435067;
    int day = 378993182;
  \end{lstlisting}

  For these values of \var{year}, \var{month} and \var{day}, the three
  dates evaluate to:

  \begin{lstlisting}[mathescape=true,showstringspaces=false]
    date1: "Sat May 02 00:00:00 CEST 31580172"
    date2: "Fri Jul 02 00:00:00 CEST 31580799"
    date3: "Fri Jul 02 00:00:00 CEST 31580799"
  \end{lstlisting}

  Where \var{date1} evaluates to a different date than \var{date2} and \var{date3}. In principle, this should not affect any user as the given
  \var{year}, \var{month} and \var{day} are clearly artificial and outside the expected domain of a calendaristic date.
  In particular, for this example, we deduced that the negative year is the cause for the different values of \var{date1}, \var{date2} and \var{date3}.

  This counterexample is enough to stop our synthesiser from finding any of the correct refactorings in Figure~\ref{ex:three-dates}.
  To overcome this problem, we plan on computing preconditions for the verification process. Namely, for this example, we would collect all the concrete values that
  \var{year}, \var{month} and \var{day} get instantiated to in the unit tests associated with the given project, and use them to
  infer a precondition over the domain of these three variables. For \var{year}, this should tell us that the expected year must be positive.
  Consequently, the verifier won't attempt to find counterexamples involving negative years, thus eliminating the counterexample above.


  
\section{Related Work}

Related paper: in \cite{DBLP:conf/paste/Perkins05}, the authors
replace calls to deprecated methods by their bodies.

Often, genetic improvement
\cite{DBLP:journals/dagstuhl-reports/PetkeGFL18} is used for the
purpose of code refactoring. Due to the manner in which such works measure
the fitness of potential refactorings, genetic improvement cannot vary
the refactoring context.  Conversely, our technique allows varying this
context until a refactoring is being found.

\paragraph{Program refactoring}

Cheung et al.~describe a system that automatically transforms fragments of
application logic into SQL queries~\cite{DBLP:conf/pldi/CheungSM13}. 
Moreover, similar to our approach, the authors rely on synthesis technology
to generate invariants and postconditions that validate their
transformations (a~similar approach is presented
in~\cite{DBLP:conf/cc/IuCZ10}).  The main difference (besides the actual
goal of the work, which is different from ours) to our work is that the
lists they operate on are immutable and do not support operations such as
remove.  Capturing the potential side effects caused by such operations is
one of our work's main challenges.

Syntax-driven refactoring base program transformation decisions
on observations on the program's syntax tree.  Visser
presents a purely syntax-driven framework~\cite{stratego}.  The
presented method is intended to be configurable for specific
refactoring tasks, but cannot provide guarantees about semantics
preservation.  The same holds for~\cite{txl} by Cordy et al.,
\cite{sawin} by Sawin et al., \cite{bae} by Bae et al.~and
\cite{chris} by Christopoulou et al.  In contrast to these approaches,
our procedure constructs an equivalence proof before transforming the
program. In \cite{conf/sigsoft/GyoriFDL13}, Gyori et al. present a
similar refactoring to ours but performed in a syntax-driven manner.
%
Steimann et al.~present Constraint-Based Refactoring in \cite{Steimann2011},
\cite{Steimann2012Pilgrim} and \cite{Steimann2011KollePilgrim}. Their approach
generates explicit constraints over the program's abstract syntax tree to
prevent compilation errors or behaviour changes by automated refactorings.
% This gives rise to a flexible framework of customisable refactorings,
% implementable through a refactoring constraint specification language
% (cf. \cite{Steimann2011KollePilgrim}).
The approach is limited by the information
a program's AST provides and thus favours conservative implementations of
syntax-focused refactorings such as \emph{Pull Up Field}.
%
Fuhrer et al.~implement a type constraint system to introduce missing type
parameters in uses of generic classes (cf. \cite{DBLP:conf/ecoop/FuhrerTKDK05})
and to introduce generic type parameters into classes which do not provide
a generic interfaces despite being used in multiple type contexts
(cf. \cite{DBLP:conf/icse/KiezunETF07}).
%
% Raychev et al.~present a semi-automatic approach where users perform
% incomplete refactorings manually and then employ a constraint solver
% to find a sequence of default refactorings such as move or rename
% which include the users' changes. The engine is limited to syntactic
% matching with the users' partial changes and does not consider program
% semantics~\cite{DBLP:conf/oopsla/RaychevSSV13}.
%
% Weissgerber and Diehl rely on meta information to classify changes
% between software versions as refactorings~\cite{weiss}.  The technique
% aims to identify past refactorings performed by programmers, but is
% not a decision procedure for automated refactorings.
%
O'Keffe and Cinn{\'{e}}ide present search-based
refactoring~\cite{search1, search2}, which is similar to syntax-driven
refactoring.  They rephrase refactoring as an optimisation problem,
using code metrics as fitness measure.  As such, the method optimises
syntactical constraints and does not take program semantics into
account.
%
% Bavota et al. implement refactoring decisions in \cite{Bavota:2011:IEC}
% using semantic information limited to identifiers and comments,
% which may differ from the actual semantics (e.g. due to bugs).
%
Kataoka et al. interpret program semantics to apply refactorings
\cite{Kataoka:2001:ASP:846228.848644}, but use dynamic test execution
rather than formal verification, and hence their transformation lacks
soundness guarantees.
%
Franklin et al. implement a pattern-based refactoring approach
transforming statements to stream queries~\cite{Gyori:2013:CGI:2491411.2491461}.
Their tool LambdaFicator~\cite{DBLP:conf/icse/FranklinGLD04} is available as a
NetBeans branch. We compared \tool against it in our experimental evaluation
in Sec.~\ref{experiments-results}.
%
%% \paragraph{Heap Logics}
%
%% While many decidable heap logics have been developed recently, none are
%% expressive enough to capture operations allowed by the Java Collection
%% interface, operations allowed by the Java Stream interface as well as
%% equality between collections (for lists this implies that we must be able to
%% reason about both content of lists and the order of
%% elements)~\cite{DBLP:conf/cav/ItzhakyBINS13, DBLP:conf/cav/PiskacWZ13,
%% DBLP:conf/esop/BrainDKS14, DBLP:conf/popl/MadhusudanPQ11,
%% DBLP:conf/atva/BouajjaniDES12, DBLP:conf/lpar/DavidKL15}.  On the other
%% hand, very expressive transitive closure
%% logics~\cite{DBLP:conf/csl/ImmermanRRSY04} are not concise and easily
%% translatable to stream code.

\paragraph{Program synthesis}

An approach to program synthesis very similar to ours is Syntax Guided
Synthesis (SyGuS)~\cite{sygus}.  SyGuS synthesisers supplement the logical
specification with a syntactic template that constrains the space of allowed
implementations.  Thus, each semantic specification is accompanied by a
syntactic specification in the form of a grammar.  Other second-order
solvers are introduced in~\cite{DBLP:conf/pldi/GrebenshchikovLPR12,
DBLP:conf/cav/BeyenePR13}.  As opposed to ours, these focus on
Horn clauses.

\section{Conclusion}

We conjecture that refactorings driven by the semantics of programs have
broader applicability and are able to address more complex refactoring
schemata in comparison to conventional syntax-driven refactorings, thereby
increasing the benefits of automated refactoring.  The space of possible
semantic refactoring methods is enormous; as an instance, we have presented
a method for refactoring iteration over Java collection classes based on
program synthesis methods.  Our experiments indicate that refactoring using
this specific instance is feasible, sound and sufficiently performant. 
Future research must broaden the evidence for our general hypothesis by
considering other programming languages, further, ideally more complex
refactoring schemata, and other semantics-based analysis techniques.

%\acks

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrv}
\bibliography{document}{}



\end{document}

%                       Revision History
%                       -------- -------
%  Date         Person  Ver.    Change
%  ----         ------  ----    ------

%  2013.06.29   TU      0.1--4  comments on permission/copyright notices

